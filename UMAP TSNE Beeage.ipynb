{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables \n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "hdf5_file = tables.open_file('pathtofile', mode='r')\n",
    "# features; 0: age; 1 bee_id; rest: normal data\n",
    "train = hdf5_file.root.train\n",
    "print(train.shape)\n",
    "hidds = []\n",
    "labels_age = []\n",
    "labels_velo = []\n",
    "printcounter = 0\n",
    "for i in range(0, 100000):\n",
    "    if (printcounter == 1000):\n",
    "        clear_output()\n",
    "        print('Progress report: ', i/100000)\n",
    "        printcounter = 0\n",
    "    printcounter += 1\n",
    "    batch_data = train[i, :, :]\n",
    "    label = batch_data[-1, :4]\n",
    "    #print(label)\n",
    "    #print(label[3])\n",
    "    p = 1 \n",
    "    labels_age.append(batch_data[-1, 6])\n",
    "    labels_velo.append(np.linalg.norm(batch_data[-1, 11:13]))\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels_age, 60)\n",
    "#plt.yscale('log')+6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels_velo, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_data(data, batchsize, shuffle=False):\n",
    "    if shuffle:\n",
    "        indices = np.arange(data.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, data.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield data[excerpt, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def log_sum_exp(x, dim=1):\n",
    "    x_max, x_argmax = x.max(dim, keepdim=True)\n",
    "    x_max_broadcast = x_max.expand(*x.size())\n",
    "    return x_max + torch.log(\n",
    "        torch.sum(torch.exp(x - x_max_broadcast), dim=dim, keepdim=True))\n",
    "\n",
    "class MDN(nn.Module):\n",
    "    \"\"\"A mixture density network layer\n",
    "    The input maps to the parameters of a MoG probability distribution, where\n",
    "    each Gaussian has O dimensions and diagonal covariance.\n",
    "    Arguments:\n",
    "        in_features (int): the number of dimensions in the input\n",
    "        out_features (int): the number of dimensions in the output\n",
    "        num_gaussians (int): the number of Gaussians per output dimensions\n",
    "    Input:\n",
    "        minibatch (BxD): B is the batch size and D is the number of input\n",
    "            dimensions.\n",
    "    Output:\n",
    "        (pi, sigma, mu) (BxG, BxGxO, BxGxO): B is the batch size, G is the\n",
    "            number of Gaussians, and O is the number of dimensions for each\n",
    "            Gaussian. Pi is a multinomial distribution of the Gaussians. Sigma\n",
    "            is the standard deviation of each Gaussian. Mu is the mean of each\n",
    "            Gaussian.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, num_gaussians):\n",
    "        super(MDN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.pi = nn.Sequential(\n",
    "            nn.Linear(in_features, num_gaussians), nn.LogSoftmax(dim=1))\n",
    "        self.sigma = nn.Linear(in_features, out_features * num_gaussians)\n",
    "        self.mu = nn.Linear(in_features, out_features * num_gaussians)\n",
    "\n",
    "    def forward(self, minibatch):\n",
    "        pi = self.pi(minibatch)\n",
    "        sigma = self.sigma(minibatch)\n",
    "        # original sigma = torch.clamp(sigma, np.log(np.sqrt(1e-4)), 1e8)\n",
    "        # working \n",
    "        sigma =  torch.clamp(sigma, np.log(np.sqrt(1e-3)), 5e1)\n",
    "        #try 3 sigma = torch.clamp(sigma, np.log(np.sqrt(1e-3)), 1e4)\n",
    "        sigma = sigma.view(-1, self.num_gaussians, self.out_features)\n",
    "        mu = self.mu(minibatch)\n",
    "        mu = mu.view(-1, self.num_gaussians, self.out_features)\n",
    "        return pi, sigma, mu\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian_probability(sigma, x_mu, x):\n",
    "        \"\"\"Returns the probability of `data` given MoG parameters `sigma` and `mu`.\n",
    "        Arguments:\n",
    "            sigma (BxGxO): The standard deviation of the Gaussians. B is the batch\n",
    "                size, G is the number of Gaussians, and O is the number of\n",
    "                dimensions per Gaussian.\n",
    "            mu (BxGxO): The means of the Gaussians. B is the batch size, G is the\n",
    "                number of Gaussians, and O is the number of dimensions per Gaussian.\n",
    "            data (BxI): A batch of data. B is the batch size and I is the number of\n",
    "                input dimensions.\n",
    "        Returns:\n",
    "            probabilities (BxG): The probability of each point in the probability\n",
    "                of the distribution in the corresponding sigma/mu index.\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(1).expand_as(sigma)\n",
    "        var = (torch.exp(sigma)**2)\n",
    "        return -((x - x_mu)**2) / (2 * var + 1e-4) - sigma - math.log(\n",
    "            math.sqrt(2 * math.pi))\n",
    "\n",
    "    @staticmethod\n",
    "    def mdn_loss(pi, sigma, mu, target):\n",
    "        \"\"\"Calculates the error, given the MoG parameters and the target\n",
    "        The loss is the negative log likelihood of the data given the MoG\n",
    "        parameters.\n",
    "        \"\"\"\n",
    "        nll = log_sum_exp(pi[:, :, None] +\n",
    "                          MDN.gaussian_probability(sigma, mu, target))\n",
    "        nll = -torch.sum(nll, dim=-1)\n",
    "        return torch.mean(nll)\n",
    "\n",
    "    @staticmethod\n",
    "    def sample(pi, sigma, mu):\n",
    "        \"\"\"Draw samples from a MoG.\n",
    "        \"\"\"\n",
    "        categorical = Categorical(torch.exp(pi))\n",
    "        pis = list(categorical.sample().data)\n",
    "        sigma = torch.exp(sigma)\n",
    "        sample = Variable(\n",
    "            sigma.data.new(sigma.size(0), sigma.size(2)).normal_())\n",
    "        for i, idx in enumerate(pis):\n",
    "            sample[i] = sample[i].mul(sigma[i, idx]).add(mu[i, idx])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    if type(model) in [nn.Linear]:\n",
    "        nn.init.xavier_normal_(model.weight.data)\n",
    "    elif type(model) in [nn.LSTM, nn.RNN, nn.GRU]:\n",
    "        nn.init.xavier_normal_(model.weight_hh_l0)\n",
    "        nn.init.xavier_normal_(model.weight_ih_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "class SimpleRNN(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_outputs):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        # 32 was used for all the simulated data\n",
    "        #hidden_dim = 32 #\n",
    "        \n",
    "        hidden_dim = 128 #hidden_dim\n",
    "\n",
    "        #self.inp = torch.nn.Linear(n_features, hidden_size)\n",
    "        num_layers = 2\n",
    "        #self.rnn = LayerNormLSTM(n_features, hidden_dim, num_layers = num_layers)\n",
    "        self.rnn = torch.nn.LSTM(n_features, hidden_dim, num_layers = num_layers)\n",
    "        \n",
    "        # 64 was used for all the simulated data\n",
    "        #self.out = torch.nn.Linear(hidden_dim, 64)\n",
    "        \n",
    "        #self.out = torch.nn.Linear(hidden_dim, 32)\n",
    "        self.mdn = MDN(hidden_dim, n_outputs, 5)\n",
    "\n",
    "        \n",
    "        #self.hidden = None\n",
    "        \n",
    "        initialize_weights(self.rnn)\n",
    "        #initialize_weights(self.out)\n",
    "        initialize_weights(self.mdn)\n",
    "\n",
    "    def step(self, inputs, hidden=None, verbose=False):\n",
    "        #input = self.inp(input)\n",
    "        if verbose:\n",
    "            print(\"Step 0:\")\n",
    "            print(inputs.shape)\n",
    "        inputs = inputs.permute([1, 0, 2])\n",
    "        if verbose:\n",
    "            print(\"Step 1:\")\n",
    "            print(inputs.shape)\n",
    "        #self.rnn.flatten_parameters()\n",
    "        output, hidden = self.rnn(inputs, hidden)\n",
    "        output = output[-1, :, :] #output[:, :, :] #output[-1, :, :]\n",
    "        #output = output.permute([1, 0, 2])\n",
    "        if verbose:\n",
    "            print(\"Step 3:\")\n",
    "            print(output.shape)\n",
    "        output = output.squeeze()\n",
    "        if verbose:\n",
    "            print(\"Step 4:\")\n",
    "            print(output.shape)\n",
    "        #output = self.out(output)\n",
    "        if verbose:\n",
    "            print(\"Step 5:\")\n",
    "            print(output.shape)\n",
    "            print(output)\n",
    "        output = self.mdn(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def forward(self, inputs, hidden=None, verbose=False):\n",
    "        if verbose:\n",
    "            print(\"inputs size: \", inputs.size)\n",
    "        batch_size = inputs.size(0)    \n",
    "        output, hidden = self.step(inputs, hidden, verbose=verbose)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_bins = 16\n",
    "#rnn = SimpleRNN(n_features=5 + (vision_bins * 8), n_outputs=4).cuda()\n",
    "rnn = SimpleRNN(n_features=5 +(vision_bins * 8), n_outputs=4).cuda()\n",
    "#rnn = torch.load('asd.pt')\n",
    "rnn = torch.load('bee40-rnn.pt')\n",
    "rnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables \n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "hdf5_file = tables.open_file('pathtofile.h5', mode='r')\n",
    "# features; 0: age; 1 bee_id; rest: normal data\n",
    "train = hdf5_file.root.train\n",
    "print(train.shape)\n",
    "hidds = []\n",
    "labels_age = []\n",
    "labels_velo = []\n",
    "printcounter = 0\n",
    "for i in range(0, 100000):\n",
    "    if (printcounter == 1000):\n",
    "        clear_output()\n",
    "        print('Progress report: ', i/100000)\n",
    "        printcounter = 0\n",
    "    printcounter += 1\n",
    "    batch_data = train[i, :, :]\n",
    "    label = batch_data[-1, :4]\n",
    "    #print(label)\n",
    "    #print(label[3])\n",
    "    p = 1 \n",
    "    if p >= np.random.uniform(0.0, 1.0):\n",
    "        batch_X = batch_data[:-1, 10:].astype(np.float32)[None, :, :]\n",
    "        batch_X = np.insert(batch_X,[1],batch_X[0],axis=0)\n",
    "        batch_X = torch.from_numpy(batch_X)\n",
    "        batch_X = torch.autograd.Variable(batch_X).cuda()\n",
    "        Y_predicted, hidden = rnn.forward(batch_X, verbose=False)\n",
    "        hidds.append(np.concatenate((hidden[0].data.cpu().numpy()[1, 0, :],hidden[1].data.cpu().numpy()[1, 0, :])))\n",
    "        labels_age.append(batch_data[-1, 6])\n",
    "        labels_velo.append(np.linalg.norm(batch_data[-1, 11:13]))\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_data[-1, :15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels_age, 60)\n",
    "#plt.yscale('log')+6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels_velo, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidds = np.asarray(hidds)\n",
    "labels_age = np.asarray(labels_age)\n",
    "labels_velo = np.asarray(labels_velo)\n",
    "print(hidds.shape)\n",
    "print(labels_age.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.manifold import TSNE\n",
    "#https://github.com/DmitryUlyanov/Multicore-TSNE}\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "X_embedded = TSNE(n_components=2, perplexity = 50).fit_transform(hidds)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], s=5, c=np.round(labels_age), cmap='nipy_spectral') #, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "cb = plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], s=0.03, c=np.round(labels_age), cmap='nipy_spectral') #, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "cb = plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "colors = ['black', 'blue', 'red', 'green']\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], s=5, c=np.round(labels_velo), cmap='nipy_spectral') #cmap='Spectral')\n",
    "cb = plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "colors = ['black', 'blue', 'red', 'green']\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], s=0.03, c=np.round(labels_velo), cmap='nipy_spectral') #cmap='Spectral')\n",
    "cb = plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "ax0 = plt.subplot(gs[0, 0])\n",
    "plt.scatter(x, y, s=20)\n",
    "\n",
    "ax1 = plt.subplot(gs[0, 1])\n",
    "cm = plt.cm.get_cmap('RdYlBu_r')\n",
    "plt.scatter(x, y, s=20 ,c=z, cmap=cm)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "cbaxes = inset_axes(ax1, width=\"30%\", height=\"3%\", loc=3) \n",
    "plt.colorbar(cax=cbaxes, ticks=[0.,1], orientation='horizontal')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "#perplexities = [0, 5, 30, 50, 100]\n",
    "(fig, subplots) = plt.subplots(1, 2, figsize=(21, 7))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "\n",
    "ax = subplots[0]\n",
    "ax.scatter(X_embedded[:, 0], X_embedded[:, 1], s=0.03, c=np.round(labels_age), cmap='nipy_spectral') #, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "#cbaxes = inset_axes(ax, width=\"30%\", height=\"3%\", loc=3) \n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n",
    "ax = subplots[1]\n",
    "ax.scatter(X_embedded[:, 0], X_embedded[:, 1], s=0.03, c=np.round(labels_velo), cmap='nipy_spectral') #cmap='Spectral')\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "#perplexities = [0, 5, 30, 50, 100]\n",
    "(fig, subplots) = plt.subplots(1, 2, figsize=(21, 7))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "\n",
    "ax = subplots[0]\n",
    "ax.scatter(X_embedded[:, 0], X_embedded[:, 1], s=0.03, c=np.round(labels_age), cmap='nipy_spectral') #, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "cbaxes = inset_axes(ax, width=\"30%\", height=\"3%\", loc=3) \n",
    "plt.colorbar(cax=cbaxes, orientation='horizontal')\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n",
    "ax = subplots[1]\n",
    "ax.scatter(X_embedded[:, 0], X_embedded[:, 1], s=0.03, c=np.round(labels_velo), cmap='nipy_spectral') #cmap='Spectral')\n",
    "cbaxes = inset_axes(ax, width=\"30%\", height=\"3%\", loc=3) \n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables \n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "hdf5_file = tables.open_file('pathtofile.h5', mode='r')\n",
    "# features; 0: age; 1 bee_id; rest: normal data\n",
    "train = hdf5_file.root.train\n",
    "print(train.shape)\n",
    "hidds_test = []\n",
    "labels_age_test = []\n",
    "labels_velo_test = []\n",
    "printcounter = 0\n",
    "for i in range(0, 70000):\n",
    "    if (printcounter == 1000):\n",
    "        clear_output()\n",
    "        print(train.shape)\n",
    "        print('Progress report: ', i/100000)\n",
    "        printcounter = 0\n",
    "    printcounter += 1\n",
    "    batch_data = train[i, :, :]\n",
    "    label = batch_data[-1, :4]\n",
    "    #print(label)\n",
    "    #print(label[3])\n",
    "    p = 1 \n",
    "    if p >= np.random.uniform(0.0, 1.0):\n",
    "        batch_X = batch_data[:-1, 10:].astype(np.float32)[None, :, :]\n",
    "        batch_X = np.insert(batch_X,[1],batch_X[0],axis=0)\n",
    "        batch_X = torch.from_numpy(batch_X)\n",
    "        batch_X = torch.autograd.Variable(batch_X).cuda()\n",
    "        Y_predicted, hidden = rnn.forward(batch_X, verbose=False)\n",
    "        hidds_test.append(np.concatenate((hidden[0].data.cpu().numpy()[1, 0, :],hidden[1].data.cpu().numpy()[1, 0, :])))\n",
    "        labels_age_test.append(batch_data[-1, 6])\n",
    "        labels_velo_test.append(np.linalg.norm(batch_data[-1, 11:13]))        \n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.asarray(hidds_test)\n",
    "labels_age_test = np.asarray(labels_age_test)\n",
    "labels_velo_test = np.asarray(labels_velo_test)\n",
    "print(test_data.shape)\n",
    "print(labels_age_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels_age_test, 60)\n",
    "#plt.yscale('log')+6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels_velo_test, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapper = umap.UMAP(min_dist=1, n_neighbors=10).fit(data, y=labels_neighs_digitzized_test)\n",
    "mapper = umap.UMAP(n_neighbors=89, min_dist=0.5).fit(hidds, y=labels_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding = mapper.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "plt.scatter(*mapper.embedding_.T, s=1, c=labels_age, cmap='nipy_spectral', alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "#cb = plt.colorbar()\n",
    "plt.title('Train data embedded via UMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "plt.scatter(*test_embedding.T, s=1, c=labels_age_test, cmap='nipy_spectral', alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "#cb = plt.colorbar()\n",
    "plt.title('Test data embedded via UMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "perplexities = [0, 5, 30, 50, 100]\n",
    "(fig, subplots) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "\n",
    "ax = subplots[0]\n",
    "#ax.set_title(\"Perplexity=%d\" % perplexity)\n",
    "ax.scatter(*mapper.embedding_.T, s=1, c=labels_age, cmap='nipy_spectral', alpha=1.0)\n",
    "#cb = plt.colorbar()\n",
    "#ax.set_title('Train data embedded via UMAP')\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n",
    "ax = subplots[1]\n",
    "ax.scatter(*test_embedding.T, s=1, c=labels_age_test, cmap='nipy_spectral', alpha=1.0)\n",
    "#ax.set_title('Test data embedded via UMAP')\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "perplexities = [0, 5, 30, 50, 100]\n",
    "(fig, subplots) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "\n",
    "ax = subplots[0]\n",
    "#ax.set_title(\"Perplexity=%d\" % perplexity)\n",
    "ax.scatter(*mapper.embedding_.T, s=0.03, c=labels_age, cmap='nipy_spectral', alpha=1.0)\n",
    "#cb = plt.colorbar()\n",
    "#ax.set_title('Train data embedded via UMAP')\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n",
    "ax = subplots[1]\n",
    "ax.scatter(*test_embedding.T, s=0.03, c=labels_age_test, cmap='nipy_spectral', alpha=1.0)\n",
    "#ax.set_title('Test data embedded via UMAP')\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapper = umap.UMAP(n_neighbors=10).fit(data, y=labels_neighs_digitzized_test)\n",
    "mapper_cool = umap.UMAP(n_neighbors=89, min_dist=0.5).fit(hidds, y=labels_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding_cool = mapper_cool.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 10))\n",
    "plt.scatter(*mapper_cool.embedding_.T, s=1, c=labels_velo, cmap='nipy_spectral', alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "cbar = plt.colorbar()\n",
    "#cbar = plt.colorbar(boundaries=np.arange(11)-0.5)\n",
    "#cbar.set_ticks(np.arange(10))\n",
    "plt.title('Train Data Embedded via UMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 10))\n",
    "plt.scatter(*test_embedding_cool.T, s=1, c=labels_velo_test, cmap='nipy_spectral', alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "cbar = plt.colorbar()\n",
    "plt.title('Data Embedded via UMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "(fig, subplots) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "\n",
    "ax = subplots[0]\n",
    "#ax.set_title(\"Perplexity=%d\" % perplexity)\n",
    "ax.scatter(*mapper_cool.embedding_.T, s=0.03, c=labels_velo, cmap='nipy_spectral', alpha=1.0)\n",
    "#cb = plt.colorbar()\n",
    "#ax.set_title('Train data embedded via UMAP')\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n",
    "ax = subplots[1]\n",
    "ax.scatter(*test_embedding_cool.T, s=0.03, c=labels_velo_test, cmap='nipy_spectral', alpha=1.0)\n",
    "#ax.set_title('Test data embedded via UMAP')\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 10))\n",
    "plt.scatter(*mapper_cool.embedding_.T, s=0.03, c=labels_age, cmap='nipy_spectral', alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "cbar = plt.colorbar()\n",
    "plt.title('Train Data Embedded via UMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 10))\n",
    "plt.scatter(*test_embedding_cool.T, s=0.03, c=labels_age_test, cmap='nipy_spectral', alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "cbar = plt.colorbar()\n",
    "plt.title('Test Data Embedded via UMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "(fig, subplots) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "fig.subplots_adjust(wspace=0.02, hspace=0.02)\n",
    "\n",
    "ax = subplots[0]\n",
    "ax.scatter(*test_embedding.T, s=0.03, c=labels_age_test, cmap='nipy_spectral', alpha=1.0)\n",
    "#ax.set_title('Test data embedded via UMAP')\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n",
    "ax = subplots[1]\n",
    "ax.scatter(*test_embedding_cool.T, s=0.03, c=labels_velo_test, cmap='nipy_spectral', alpha=1.0)\n",
    "#ax.set_title('Test data embedded via UMAP')\n",
    "ax.xaxis.set_major_formatter(NullFormatter())\n",
    "ax.yaxis.set_major_formatter(NullFormatter())\n",
    "ax.axis('tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
