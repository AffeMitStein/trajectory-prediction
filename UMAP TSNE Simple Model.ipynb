{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_data(data, batchsize, shuffle=False):\n",
    "    if shuffle:\n",
    "        indices = np.arange(data.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, data.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield data[excerpt, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def log_sum_exp(x, dim=1):\n",
    "    x_max, x_argmax = x.max(dim, keepdim=True)\n",
    "    x_max_broadcast = x_max.expand(*x.size())\n",
    "    return x_max + torch.log(\n",
    "        torch.sum(torch.exp(x - x_max_broadcast), dim=dim, keepdim=True))\n",
    "\n",
    "class MDN(nn.Module):\n",
    "    \"\"\"A mixture density network layer\n",
    "    The input maps to the parameters of a MoG probability distribution, where\n",
    "    each Gaussian has O dimensions and diagonal covariance.\n",
    "    Arguments:\n",
    "        in_features (int): the number of dimensions in the input\n",
    "        out_features (int): the number of dimensions in the output\n",
    "        num_gaussians (int): the number of Gaussians per output dimensions\n",
    "    Input:\n",
    "        minibatch (BxD): B is the batch size and D is the number of input\n",
    "            dimensions.\n",
    "    Output:\n",
    "        (pi, sigma, mu) (BxG, BxGxO, BxGxO): B is the batch size, G is the\n",
    "            number of Gaussians, and O is the number of dimensions for each\n",
    "            Gaussian. Pi is a multinomial distribution of the Gaussians. Sigma\n",
    "            is the standard deviation of each Gaussian. Mu is the mean of each\n",
    "            Gaussian.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, num_gaussians):\n",
    "        super(MDN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.pi = nn.Sequential(\n",
    "            nn.Linear(in_features, num_gaussians), nn.LogSoftmax(dim=1))\n",
    "        self.sigma = nn.Linear(in_features, out_features * num_gaussians)\n",
    "        self.mu = nn.Linear(in_features, out_features * num_gaussians)\n",
    "\n",
    "    def forward(self, minibatch):\n",
    "        pi = self.pi(minibatch)\n",
    "        sigma = self.sigma(minibatch)\n",
    "        # original sigma = torch.clamp(sigma, np.log(np.sqrt(1e-4)), 1e8)\n",
    "        # working \n",
    "        sigma =  torch.clamp(sigma, np.log(np.sqrt(1e-3)), 5e1)\n",
    "        #try 3 sigma = torch.clamp(sigma, np.log(np.sqrt(1e-3)), 1e4)\n",
    "        sigma = sigma.view(-1, self.num_gaussians, self.out_features)\n",
    "        mu = self.mu(minibatch)\n",
    "        mu = mu.view(-1, self.num_gaussians, self.out_features)\n",
    "        return pi, sigma, mu\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian_probability(sigma, x_mu, x):\n",
    "        \"\"\"Returns the probability of `data` given MoG parameters `sigma` and `mu`.\n",
    "        Arguments:\n",
    "            sigma (BxGxO): The standard deviation of the Gaussians. B is the batch\n",
    "                size, G is the number of Gaussians, and O is the number of\n",
    "                dimensions per Gaussian.\n",
    "            mu (BxGxO): The means of the Gaussians. B is the batch size, G is the\n",
    "                number of Gaussians, and O is the number of dimensions per Gaussian.\n",
    "            data (BxI): A batch of data. B is the batch size and I is the number of\n",
    "                input dimensions.\n",
    "        Returns:\n",
    "            probabilities (BxG): The probability of each point in the probability\n",
    "                of the distribution in the corresponding sigma/mu index.\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(1).expand_as(sigma)\n",
    "        var = (torch.exp(sigma)**2)\n",
    "        return -((x - x_mu)**2) / (2 * var + 1e-4) - sigma - math.log(\n",
    "            math.sqrt(2 * math.pi))\n",
    "\n",
    "    @staticmethod\n",
    "    def mdn_loss(pi, sigma, mu, target):\n",
    "        \"\"\"Calculates the error, given the MoG parameters and the target\n",
    "        The loss is the negative log likelihood of the data given the MoG\n",
    "        parameters.\n",
    "        \"\"\"\n",
    "        nll = log_sum_exp(pi[:, :, None] +\n",
    "                          MDN.gaussian_probability(sigma, mu, target))\n",
    "        nll = -torch.sum(nll, dim=-1)\n",
    "        return torch.mean(nll)\n",
    "\n",
    "    @staticmethod\n",
    "    def sample(pi, sigma, mu):\n",
    "        \"\"\"Draw samples from a MoG.\n",
    "        \"\"\"\n",
    "        categorical = Categorical(torch.exp(pi))\n",
    "        pis = list(categorical.sample().data)\n",
    "        sigma = torch.exp(sigma)\n",
    "        sample = Variable(\n",
    "            sigma.data.new(sigma.size(0), sigma.size(2)).normal_())\n",
    "        for i, idx in enumerate(pis):\n",
    "            sample[i] = sample[i].mul(sigma[i, idx]).add(mu[i, idx])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    if type(model) in [nn.Linear]:\n",
    "        nn.init.xavier_normal_(model.weight.data)\n",
    "    elif type(model) in [nn.LSTM, nn.RNN, nn.GRU]:\n",
    "        nn.init.xavier_normal_(model.weight_hh_l0)\n",
    "        nn.init.xavier_normal_(model.weight_ih_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "class SimpleRNN(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_outputs):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        # 32 was used for all the simulated data\n",
    "        #hidden_dim = 32 #\n",
    "        \n",
    "        hidden_dim = 128 #hidden_dim\n",
    "\n",
    "        #self.inp = torch.nn.Linear(n_features, hidden_size)\n",
    "        num_layers = 2\n",
    "        #self.rnn = LayerNormLSTM(n_features, hidden_dim, num_layers = num_layers)\n",
    "        self.rnn = torch.nn.LSTM(n_features, hidden_dim, num_layers = num_layers)\n",
    "        \n",
    "        # 64 was used for all the simulated data\n",
    "        #self.out = torch.nn.Linear(hidden_dim, 64)\n",
    "        \n",
    "        #self.out = torch.nn.Linear(hidden_dim, 32)\n",
    "        self.mdn = MDN(hidden_dim, n_outputs, 5)\n",
    "\n",
    "        \n",
    "        #self.hidden = None\n",
    "        \n",
    "        initialize_weights(self.rnn)\n",
    "        #initialize_weights(self.out)\n",
    "        initialize_weights(self.mdn)\n",
    "\n",
    "    def step(self, inputs, hidden=None, verbose=False):\n",
    "        #input = self.inp(input)\n",
    "        if verbose:\n",
    "            print(\"Step 0:\")\n",
    "            print(inputs.shape)\n",
    "        inputs = inputs.permute([1, 0, 2])\n",
    "        if verbose:\n",
    "            print(\"Step 1:\")\n",
    "            print(inputs.shape)\n",
    "        #self.rnn.flatten_parameters()\n",
    "        output, hidden = self.rnn(inputs, hidden)\n",
    "        output = output[-1, :, :] #output[:, :, :] #output[-1, :, :]\n",
    "        #output = output.permute([1, 0, 2])\n",
    "        if verbose:\n",
    "            print(\"Step 3:\")\n",
    "            print(output.shape)\n",
    "        output = output.squeeze()\n",
    "        if verbose:\n",
    "            print(\"Step 4:\")\n",
    "            print(output.shape)\n",
    "        #output = self.out(output)\n",
    "        if verbose:\n",
    "            print(\"Step 5:\")\n",
    "            print(output.shape)\n",
    "            print(output)\n",
    "        output = self.mdn(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def forward(self, inputs, hidden=None, verbose=False):\n",
    "        if verbose:\n",
    "            print(\"inputs size: \", inputs.size)\n",
    "        batch_size = inputs.size(0)    \n",
    "        output, hidden = self.step(inputs, hidden, verbose=verbose)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_bins = 16\n",
    "#rnn = SimpleRNN(n_features=5 + (vision_bins * 8), n_outputs=4).cuda()\n",
    "rnn = SimpleRNN(n_features=5 +(vision_bins * 8), n_outputs=4).cuda()\n",
    "#rnn = torch.load('asd.pt')\n",
    "rnn = torch.load('simplemodel-rnn.pt')\n",
    "rnn.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-SNE Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables\n",
    "hdf5_file = tables.open_file('pathtofile.h5', mode='r')\n",
    "train = hdf5_file.root.train\n",
    "print(train.shape)\n",
    "labels = []\n",
    "for i in range(0, 5100):\n",
    "    batch_data = train[i, :, :]\n",
    "    print(batch_data[-1, 0:4])\n",
    "    #labels.append(np.where(np.array([1, 0, 1, 0]) == 1)) # np.where(batch_data[:, 0:4] == 1))\n",
    "    for l in  np.where(batch_data[-1, 0:4] == 1)[0]:\n",
    "        labels.append(l)\n",
    "        print(l)\n",
    "\n",
    "labels = np.asarray(labels)\n",
    "print(\"lshape\", labels.shape)\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "# array = np.array([self.getX(), self.getY(), self.orientation, 0.333, 0, 0, \n",
    "#                          0, dx, d<y, np.cos(self.orientation), np.sin(self.orientation)])\n",
    "#        self.history.append(np.concatenate([np.concatenate([self.label, array]), self.vision]))#\n",
    "\n",
    "print(\"labels: \", unique)\n",
    "print(\"counts: \", counts)\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in np.where(np.array([0, 0, 1, 0]) == 1)[0]:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables \n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "hdf5_file = tables.open_file('pathtofile.h5', mode='r')\n",
    "# features; 0: age; 1 bee_id; rest: normal data\n",
    "train = hdf5_file.root.train\n",
    "print(train.shape)\n",
    "hidds = []\n",
    "labels = []\n",
    "labels_wall = []\n",
    "printcounter = 0\n",
    "for i in range(0, 100000):\n",
    "    if (printcounter == 1000):\n",
    "        clear_output()\n",
    "        print('Progress report: ', i/100000)\n",
    "        printcounter = 0\n",
    "    printcounter += 1\n",
    "    batch_data = train[i, :, :]\n",
    "    label = batch_data[-1, :4]\n",
    "    p = 1 \n",
    "    if p >= np.random.uniform(0.0, 1.0):\n",
    "        batch_X = batch_data[:-1, 10:].astype(np.float32)[None, :, :]\n",
    "        batch_X = np.insert(batch_X,[1],batch_X[0],axis=0)\n",
    "        batch_X = torch.from_numpy(batch_X)\n",
    "        batch_X = torch.autograd.Variable(batch_X).cuda()\n",
    "        Y_predicted, hidden = rnn.forward(batch_X, verbose=False)\n",
    "        hidds.append(np.concatenate((hidden[0].data.cpu().numpy()[1, 0, :],hidden[1].data.cpu().numpy()[1, 0, :])))\n",
    "        if np.where(label == 1)[0].shape[0] > 1:\n",
    "            labels.append(np.where(label == 1)[0][1] + 1)\n",
    "        elif np.where(label == 1)[0].shape[0] > 0:\n",
    "            labels.append(np.where(label == 1)[0][0] + 1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        if np.sum(label) > 0:\n",
    "            labels_wall.append(1)\n",
    "        else:\n",
    "            labels_wall.append(0)\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2)\n",
    "money = np.histogram(labels_wall, bins= [0, 1, 2])[0]\n",
    "\n",
    "\n",
    "def millions(x, pos):\n",
    "    'The two args are the value and tick position'\n",
    "    return '$%1.1fM' % (x * 1e-6)\n",
    "\n",
    "\n",
    "#formatter = FuncFormatter(millions)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "#ax.yaxis.set_major_formatter(formatter)\n",
    "plt.bar(x, money)\n",
    "plt.xticks(x, ('normal walk', 'avoid wall'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidds = np.asarray(hidds)\n",
    "labels = np.asarray(labels)\n",
    "labels_wall = np.asarray(labels_wall)\n",
    "print(hidds.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.manifold import TSNE\n",
    "#https://github.com/DmitryUlyanov/Multicore-TSNE}\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "\n",
    "X_embedded = TSNE(n_components=2, perplexity = 50).fit_transform(hidds)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "colors = ['blue', 'red']\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=np.round(labels_wall), cmap=matplotlib.colors.ListedColormap(colors), s=2)\n",
    "red_patch = mpatches.Patch(color='red', label='avoid wall')\n",
    "blue_patch = mpatches.Patch(color='blue', label='normal walk')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter\n",
    "import time\n",
    "\n",
    "perplexities = [0, 5, 30, 50, 100]\n",
    "(fig, subplots) = plt.subplots(1, len(perplexities), figsize=(15, 8))\n",
    "\n",
    "\n",
    "for i, perplexity in enumerate(perplexities):\n",
    "    ax = subplots[i]\n",
    "\n",
    "    t0 = time.time()\n",
    "    X_embedded = TSNE(n_components=2, perplexity = perplexity).fit_transform(hidds)\n",
    "    t1 = time.time()\n",
    "    print(\"circles, perplexity=%d in %.2g sec\" % (perplexity, t1 - t0))\n",
    "    ax.set_title(\"Perplexity=%d\" % perplexity)\n",
    "    ax.scatter(X_embedded[:, 0], X_embedded[:, 1], s=5, c=np.round(labels), cmap=matplotlib.colors.ListedColormap(colors))\n",
    "    ax.xaxis.set_major_formatter(NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    ax.axis('tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables \n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "hdf5_file = tables.open_file('pathtofile.h5', mode='r')\n",
    "# features; 0: age; 1 bee_id; rest: normal data\n",
    "train = hdf5_file.root.train\n",
    "print(train.shape)\n",
    "hidds = []\n",
    "labels = []\n",
    "labels_wall = []\n",
    "printcounter = 0\n",
    "for i in range(0, 2500):\n",
    "    if (printcounter == 1000):\n",
    "        clear_output()\n",
    "        print('Progress report: ', i/100000)\n",
    "        printcounter = 0\n",
    "    printcounter += 1\n",
    "    batch_data = train[i, :, :]\n",
    "    label = batch_data[-1, :4]\n",
    "    p = 1 \n",
    "    if p >= np.random.uniform(0.0, 1.0):\n",
    "        batch_X = batch_data[:-1, 10:].astype(np.float32)[None, :, :]\n",
    "        batch_X = np.insert(batch_X,[1],batch_X[0],axis=0)\n",
    "        batch_X = torch.from_numpy(batch_X)\n",
    "        batch_X = torch.autograd.Variable(batch_X).cuda()\n",
    "        Y_predicted, hidden = rnn.forward(batch_X, verbose=False)\n",
    "        hidds.append(np.concatenate((hidden[0].data.cpu().numpy()[1, 0, :],hidden[1].data.cpu().numpy()[1, 0, :])))\n",
    "        if np.where(label == 1)[0].shape[0] > 1:\n",
    "            labels.append(np.where(label == 1)[0][1] + 1)\n",
    "        elif np.where(label == 1)[0].shape[0] > 0:\n",
    "            labels.append(np.where(label == 1)[0][0] + 1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        if np.sum(label) > 0:\n",
    "            labels_wall.append(1)\n",
    "        else:\n",
    "            labels_wall.append(0)\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidds = np.asarray(hidds)\n",
    "labels = np.asarray(labels)\n",
    "labels_wall = np.asarray(labels_wall)\n",
    "print(hidds.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.fit_transform(hidds)\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding[:, 0], embedding[:, 1], c=labels_wall, cmap='Spectral', s=2)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.colorbar(boundaries=np.arange(6)-0.5).set_ticks(np.arange(5))\n",
    "plt.title('UMAP projection with normal Labels', fontsize=24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP WITH LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables \n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "hdf5_file = tables.open_file('pathtofile.h5', mode='r')\n",
    "# features; 0: age; 1 bee_id; rest: normal data\n",
    "train = hdf5_file.root.train\n",
    "print(train.shape)\n",
    "hidds = []\n",
    "labels = []\n",
    "labels_wall = []\n",
    "printcounter = 0\n",
    "for i in range(0, 100000):\n",
    "    if (printcounter == 1000):\n",
    "        clear_output()\n",
    "        print('Progress report: ', i/100000)\n",
    "        printcounter = 0\n",
    "    printcounter += 1\n",
    "    batch_data = train[i, :, :]\n",
    "    label = batch_data[-1, :4]\n",
    "    p = 1 \n",
    "    if p >= np.random.uniform(0.0, 1.0):\n",
    "        batch_X = batch_data[:-1, 10:].astype(np.float32)[None, :, :]\n",
    "        batch_X = np.insert(batch_X,[1],batch_X[0],axis=0)\n",
    "        batch_X = torch.from_numpy(batch_X)\n",
    "        batch_X = torch.autograd.Variable(batch_X).cuda()\n",
    "        Y_predicted, hidden = rnn.forward(batch_X, verbose=False)\n",
    "        hidds.append(np.concatenate((hidden[0].data.cpu().numpy()[1, 0, :],hidden[1].data.cpu().numpy()[1, 0, :])))\n",
    "        if np.where(label == 1)[0].shape[0] > 1:\n",
    "            labels.append(np.where(label == 1)[0][1] + 1)\n",
    "        elif np.where(label == 1)[0].shape[0] > 0:\n",
    "            labels.append(np.where(label == 1)[0][0] + 1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        if np.sum(label) > 0:\n",
    "            labels_wall.append(1)\n",
    "        else:\n",
    "            labels_wall.append(0)\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(hidds)\n",
    "labels = np.asarray(labels)\n",
    "labels_wall = np.asarray(labels_wall)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables \n",
    "import numpy as np\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "\n",
    "hdf5_file = tables.open_file('pathtofile.h5', mode='r')\n",
    "# features; 0: age; 1 bee_id; rest: normal data\n",
    "train = hdf5_file.root.train\n",
    "print(train.shape)\n",
    "hidds_test = []\n",
    "labels_test = []\n",
    "labels_wall_test = []\n",
    "printcounter = 0\n",
    "for i in range(0, 25000):\n",
    "    if (printcounter == 1000):\n",
    "        clear_output()\n",
    "        print('Progress report: ', i/100000)\n",
    "        printcounter = 0\n",
    "    printcounter += 1\n",
    "    batch_data = train[i, :, :]\n",
    "    label = batch_data[-1, :4]\n",
    "    p = 1 \n",
    "    if p >= np.random.uniform(0.0, 1.0):\n",
    "        batch_X = batch_data[:-1, 10:].astype(np.float32)[None, :, :]\n",
    "        batch_X = np.insert(batch_X,[1],batch_X[0],axis=0)\n",
    "        batch_X = torch.from_numpy(batch_X)\n",
    "        batch_X = torch.autograd.Variable(batch_X).cuda()\n",
    "        Y_predicted, hidden = rnn.forward(batch_X, verbose=False)\n",
    "        hidds_test.append(np.concatenate((hidden[0].data.cpu().numpy()[1, 0, :],hidden[1].data.cpu().numpy()[1, 0, :])))\n",
    "        if np.where(label == 1)[0].shape[0] > 1:\n",
    "            labels_test.append(np.where(label == 1)[0][1] + 1)\n",
    "        elif np.where(label == 1)[0].shape[0] > 0:\n",
    "            labels_test.append(np.where(label == 1)[0][0] + 1)\n",
    "        else:\n",
    "            labels_test.append(0)\n",
    "        if np.sum(label) > 0:\n",
    "            labels_wall_test.append(1)\n",
    "        else:\n",
    "            labels_wall_test.append(0)\n",
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.asarray(hidds_test)\n",
    "labels_wall_test = np.asarray(labels_wall_test)\n",
    "print(test_data.shape)\n",
    "print(labels_wall_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapper = umap.UMAP(min_dist=1, n_neighbors=10).fit(data, y=labels_neighs_digitzized_test)\n",
    "mapper = umap.UMAP(n_neighbors=19).fit(data, y=labels_wall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding = mapper.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'red']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 10))\n",
    "plt.scatter(*mapper.embedding_.T, s=3, c=labels_wall, cmap=matplotlib.colors.ListedColormap(colors), alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "red_patch = mpatches.Patch(color='red', label='avoid wall')\n",
    "blue_patch = mpatches.Patch(color='blue', label='normal walk')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "plt.title('Train Data Embedded via UMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(14, 10))\n",
    "plt.scatter(*test_embedding.T, s=3, c=labels_wall_test, cmap=matplotlib.colors.ListedColormap(colors), alpha=1.0)\n",
    "plt.setp(ax, xticks=[], yticks=[])\n",
    "red_patch = mpatches.Patch(color='red', label='avoid wall')\n",
    "blue_patch = mpatches.Patch(color='blue', label='normal walk')\n",
    "plt.legend(handles=[red_patch, blue_patch])\n",
    "plt.title('Data Embedded via UMAP');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
