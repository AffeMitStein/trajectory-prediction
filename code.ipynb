{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "from graphics import *\n",
    "from datetime import timedelta, datetime, date\n",
    "from scipy import spatial\n",
    "import tables\n",
    "import time\n",
    "from time import sleep\n",
    "from scipy.ndimage.filters import gaussian_filter1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "connect_str = \"\"\"dbname='beesbook' user='mehmed' host='localhost' password='bbvision' application_name='memel'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def angle_between(p1, p2):\n",
    "    ang1 = np.arctan2(*p1[::-1])\n",
    "    ang2 = np.arctan2(*p2[::-1])\n",
    "    angle_360 = np.rad2deg((ang1 - ang2) % (2 * np.pi))\n",
    "    if angle_360 <= 180:\n",
    "        return angle_360\n",
    "    else:\n",
    "        return -1*(360 - angle_360)\n",
    "\n",
    "vecA = np.array([-1,0])\n",
    "vecB = np.array([2,1])\n",
    "print(angle_between(vecA, vecB))\n",
    "print(np.rad2deg(np.arctan2(*vecB[::-1])))\n",
    "\n",
    "def angle_between_rad_vec(rad, vec):\n",
    "    ang1 = rad\n",
    "    ang2 = np.arctan2(*vec[::-1])\n",
    "    angle_360 = np.rad2deg((ang1 - ang2) % (2 * np.pi))\n",
    "    if angle_360 <= 180:\n",
    "        return np.deg2rad(angle_360)\n",
    "    else:\n",
    "        return np.deg2rad(-1*(360 - angle_360))\n",
    "\n",
    "print(\"anglebetweenradvec\", angle_between_rad_vec(1, vecA))\n",
    "\n",
    "    \n",
    "def angle_between_rad(ang1, ang2):\n",
    "    # returns diffrence in radian\n",
    "    angle_360 = np.rad2deg((ang1 - ang2) % (2 * np.pi))\n",
    "    if angle_360 <= 180:\n",
    "        return np.deg2rad(angle_360)\n",
    "    else:\n",
    "        return np.deg2rad(-1*(360 - angle_360))\n",
    "    \n",
    "def get_bee_2D_vision(posX, posY, orientation, neighbour_positions, max_visual_range, num_bins = 36):\n",
    "    \"\"\"\n",
    "    Seperate environment of an agent into bins and find nearest neighbour for all bins.\n",
    "    \"\"\"\n",
    "    bins = np.zeros(num_bins)\n",
    "    borders = np.linspace(-180, 180, num_bins + 1)\n",
    "    sight_vectors = [neighbour_pos[:2] - np.array([posX, posY]) for neighbour_pos in neighbour_positions]\n",
    "    angles = [[angle_between_rad_vec(orientation, sight_vector), sight_vector] for sight_vector in sight_vectors]\n",
    "    for angle in angles:\n",
    "        if (np.linalg.norm(angle[1])!=0):\n",
    "            for i in range(len(borders)-1):\n",
    "                if angle[0] <= borders[i+1]:\n",
    "                    bins[i] = max([bins[i], (max_visual_range - np.linalg.norm(angle[1]))/max_visual_range]) \n",
    "                    break\n",
    "\n",
    "                    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(vec, norm):\n",
    "    \"\"\"Normalizes the vector and multiplies it with norm.\"\"\"\n",
    "    return(norm*vec/np.linalg.norm(vec))\n",
    "\n",
    "\n",
    "def turn_vector(vec, angle):\n",
    "    x, y = vec\n",
    "    x_new = x*np.cos(angle) - y*np.sin(angle)\n",
    "    y_new = x*np.sin(angle) + y*np.cos(angle)\n",
    "    vec_new = np.array((x_new, y_new))\n",
    "    return vec_new\n",
    "\n",
    "def get_wall_intersection(position, direction, borders):\n",
    "    s = np.inf\n",
    "    # make numpy arrays\n",
    "    if type(position) == list:\n",
    "        position = np.array(position)\n",
    "    if type(direction) == list:\n",
    "        direction = np.array(direction)\n",
    "    if type(borders) == list:\n",
    "        borders = np.array(borders)\n",
    "    for point in borders:\n",
    "        s_tmp = (point[0] - position[0])/direction[0]\n",
    "        if s_tmp < 0:\n",
    "            s_tmp = np.inf\n",
    "        s = min(s, s_tmp)\n",
    "        s_tmp = (point[1] - position[1]) / direction[1]\n",
    "        if s_tmp < 0:\n",
    "            s_tmp = np.inf\n",
    "        s = min(s, s_tmp)\n",
    "    intersection_point = position + s * direction\n",
    "    return intersection_point\n",
    "\n",
    "def get_walls_in_sight(position, orientation, radius, num_bins = 16, borders=[[0,0], [370, 370]]):\n",
    "    \"\"\"\n",
    "    Ray tracing in order to detect walls.\n",
    "    \"\"\"\n",
    "    bins = np.zeros(num_bins)\n",
    "    bin_distance = 360/num_bins\n",
    "    angles = np.linspace(-180+bin_distance/2, 180-bin_distance/2, num_bins, endpoint=True)\n",
    "    angles = np.radians(angles)\n",
    "    osin = np.sin(orientation)\n",
    "    ocos = np.cos(orientation)\n",
    "    target_dirs = [normalize(turn_vector(np.array([osin, ocos]), angle), radius) for angle in angles]\n",
    "    for i, direction in enumerate(target_dirs):\n",
    "        intersection_point = get_wall_intersection(position, direction, borders)\n",
    "        bins[i] = max(0, 1 - np.linalg.norm(position-intersection_point)/radius)\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class OneStepBeeHistory:\n",
    "    \n",
    "    # if bee_id's were unique per timestamp it would make much more sense \n",
    "    #to use bee_ids, but that is currently not the case\n",
    "    def __init__(self, numberOfFeatures, track_ids):\n",
    "        self.history = np.ones((2, len(track_ids), numberOfFeatures)) * (-1)\n",
    "        self.bee_indicies = {}\n",
    "        for i, key in enumerate(track_ids):\n",
    "            self.bee_indicies[int(key)] = i\n",
    "            \n",
    "    def getKeys(self):\n",
    "        return self.bee_indicies.keys()\n",
    "\n",
    "    def save(self, track_id, bee):\n",
    "        bee_index = self.bee_indicies[int(track_id)]\n",
    "        self.history[0, bee_index, :] = self.history[1, bee_index, :]\n",
    "        self.history[1, bee_index, :] = bee[:]\n",
    "        \n",
    "    def getMovement(self, track_id):\n",
    "        bee_index = self.bee_indicies[track_id]\n",
    "        if (self.history[0, bee_index, 3] == -1):\n",
    "            # no history before this timestamp\n",
    "            return 0, 0\n",
    "        dx = self.history[1, bee_index, 0] - self.history[0, bee_index, 0]\n",
    "        dy = self.history[1, bee_index, 1] - self.history[0, bee_index, 1]\n",
    "        return dx, dy \n",
    "    \n",
    "    def getOrientation(self, track_id):\n",
    "        bee_index = self.bee_indicies[track_id]\n",
    "        if (self.history[0, bee_index, 3] == -1):\n",
    "            # no history before this timestamp\n",
    "            return 0\n",
    "        do = angle_between_rad(self.history[1, bee_index, 2], self.history[0, bee_index, 2])\n",
    "        return do\n",
    "       \n",
    "\n",
    "    def getActivity(self, track_id, verbose = True):\n",
    "        bee_index = self.bee_indicies[track_id]\n",
    "        if (self.history[0, bee_index, 3] == -1):\n",
    "            # no history before this timestamp\n",
    "            return 0\n",
    "        x0 = self.history[0, bee_index, 0]\n",
    "        y0 = self.history[0, bee_index, 1]\n",
    "        x1 = self.history[1, bee_index, 0]\n",
    "        y1 = self.history[1, bee_index, 1]\n",
    "        vectorLength = np.sqrt((x1-x0)*(x1-x0) + (y1-y0)*(y1-y0))\n",
    "        dt = self.history[1, bee_index, 3] - self.history[0, bee_index, 3]\n",
    "        if (dt < 1/3):\n",
    "            dt = 0.3333333\n",
    "            #print(\"UNSOUND DATA\")\n",
    "            #return 0\n",
    "        if (verbose and vectorLength/(dt) > 100):\n",
    "            print(\"INFOS:\")\n",
    "            print(\"timestep: \", self.history[0, bee_index, 3])\n",
    "            print(\"bee id: \", self.history[0, bee_index, 5])\n",
    "            print(\"vectorLength\", vectorLength)\n",
    "            print(\"avrg speed: \", vectorLength/(dt))\n",
    "            print(\"dt: \", dt)\n",
    "            print(\"x0, y0: \", x0, \", \", y0)\n",
    "            print(\"x1, y1: \", x1, \", \", y1)\n",
    "        return vectorLength/(dt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getBeeSurroundings(currBee, neighbour_positions, history, max_visual_range, num_bins = 36, verbose = True, borders=[[0,0], [370, 370]]):\n",
    "    \"\"\"\n",
    "    Seperate environment of an agent into bins and find nearest neighbour for all bins.\n",
    "    Add orientation and activity of the neighbour bees.\n",
    "    \"\"\"\n",
    "    posX = currBee[0]\n",
    "    posY = currBee[1]\n",
    "    orientation = currBee[2]\n",
    "    bins_distance = np.zeros(num_bins)\n",
    "    bins_SINorientation = np.zeros(num_bins)\n",
    "    bins_COSorientation = np.zeros(num_bins)\n",
    "    bins_activity = np.zeros(num_bins)\n",
    "    bins_binary = np.zeros(num_bins)\n",
    "    bins_relativeOsin = np.zeros(num_bins)\n",
    "    bins_relativeOcos= np.zeros(num_bins)\n",
    "    borders = get_walls_in_sight(np.array([posX, posY]), orientation, max_visual_range, num_bins, borders)\n",
    "    angle_borders = np.linspace(-180, 180, num_bins + 1)\n",
    "    sight_vectors = [[neighbour_pos[:2] - np.array([posX, posY]), neighbour_pos ]for neighbour_pos in neighbour_positions]\n",
    "    angles = [[angle_between_rad_vec(orientation, sight_vector[0]), sight_vector[0], sight_vector[1]] for sight_vector in sight_vectors]\n",
    "    for angle in angles:\n",
    "        nbee_angle = angle[0] # based on this angle do bin seperation\n",
    "        sight_vector = angle[1] # the sight vector\n",
    "        nbee = angle[2] # neighbour bee\n",
    "        if (np.linalg.norm(sight_vector)!=0):\n",
    "            for i in range(len(angle_borders)-1):\n",
    "                if nbee_angle <= angle_borders[i+1]:\n",
    "                    if (bins_distance[i] < ((max_visual_range - np.linalg.norm(sight_vector))/max_visual_range)):\n",
    "                        bins_distance[i] = (max_visual_range - np.linalg.norm(sight_vector))/max_visual_range\n",
    "                        oBeeOrientation = nbee[2]\n",
    "                        # sin and cos of angle \n",
    "                        od = orientation #angle_between_rad(orientation, oBeeOrientation)\n",
    "                        bins_SINorientation[i] = np.sin(od)\n",
    "                        bins_COSorientation[i] = np.cos(od)\n",
    "                        track_id = nbee[4]\n",
    "                        # TODO: check this\n",
    "                        activity = history.getActivity(track_id, verbose)\n",
    "                        bins_activity[i] = activity\n",
    "                        bins_binary[i] = 1\n",
    "                        # take vector that would look at me\n",
    "                        # look how much sight vector is away from it\n",
    "                        mOMrad = np.arctan2(currBee[0] - nbee[0], currBee[1] - nbee[1])\n",
    "                        relativeO = angle_between_rad(oBeeOrientation, mOMrad)\n",
    "                        bins_relativeOsin[i] = np.sin(relativeO)\n",
    "                        bins_relativeOcos[i] = np.cos(relativeO)\n",
    "                    break\n",
    "    bins_distance = gaussian_filter1d(bins_distance, 0.4, mode='wrap')\n",
    "    bins_activity = gaussian_filter1d(bins_activity, 0.4, mode='wrap')\n",
    "    bins_binary = gaussian_filter1d(bins_binary, 0.4, mode='wrap')\n",
    "    bins = np.concatenate((bins_distance, bins_SINorientation, bins_COSorientation, bins_activity, bins_binary, bins_relativeOsin, bins_relativeOcos, borders), axis = 0)\n",
    "    #bins = np.append(np.append(np.append(np.append(np.append(np.append(np.append(bins_distance, bins_SINorientation), bins_COSorientation), bins_activity), bins_binary), bins_relativeOsin), bins_relativeOcos), borders)\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def transformCordinateSystem(o, dx, dy):\n",
    "    x = np.cos(o) * dx - np.sin(o) * dy\n",
    "    y = np.sin(o) * dx + np.cos(o) * dy\n",
    "    return x, y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getLength(x, y):\n",
    "    return np.sqrt(x*x + y*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getData(querystring):\n",
    "    start = time.time()\n",
    "    with psycopg2.connect(connect_str) as conn:\n",
    "        with conn.cursor('db_cursor', cursor_factory=psycopg2.extras.DictCursor) as cur:\n",
    "            cur.execute(querystring)          \n",
    "            data = cur.fetchall()\n",
    "    print(len(data))\n",
    "    end = time.time()\n",
    "    print(\"Time in seconds: \", end - start)\n",
    "\n",
    "    data = np.asarray(data)\n",
    "    print(\"Data shape: \", data.shape)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starts[i] and stops[i] (starts[i] < stops[i]) should be intervals that are used for training generation. \n",
    "# large intervals should be avoided, because RAM might get filled \n",
    "# 2 Hour window with 16 bins -> 16 gigs needed \n",
    "starts = np.array(['2016-08-24 00:00:00', '2016-08-24 04:00:00', '2016-08-24 06:00:00'\n",
    "                  , '2016-08-24 08:00:00', '2016-08-24 12:00:00', '2016-08-24 14:00:00'\n",
    "                  , '2016-08-24 18:00:00']) \n",
    "stops  = np.array(['2016-08-24 01:00:00', '2016-08-24 05:00:00', '2016-08-24 07:00:00'\n",
    "                  , '2016-08-24 09:00:00', '2016-08-24 13:00:00', '2016-08-24 15:00:00'\n",
    "                  , '2016-08-24 19:00:00'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import bb_utils.meta as bbmeta\n",
    "import bb_utils.ids as bbids\n",
    "import pandas as pd\n",
    "\n",
    "BeeMeta = bbmeta.BeeMetaInfo()\n",
    "max_visual_range = 20\n",
    "bee_vision_bins = 16\n",
    "bins_size = bee_vision_bins*8\n",
    "num_features = bins_size+ 6\n",
    "save_file_path = 'pathoffile.h5'\n",
    "time_length = 40 #35\n",
    "img_dtype = tables.Float64Atom()  # dtype in which the images will be saved\n",
    "data_shape = (0, time_length - 1, bins_size+5 + 6 + 4)\n",
    "hdf5_file = tables.open_file(save_file_path, mode='w')\n",
    "hdf5_file.create_earray(hdf5_file.root, 'train', img_dtype, shape = data_shape)\n",
    "hdf5_file.close()\n",
    "track_movs = []\n",
    "agenulls = 0\n",
    "for i in range(0, len(starts)):\n",
    "    print(\"Interval: \", i, \"/\", len(starts))\n",
    "    start = '\\'' + starts[i] + '\\''\n",
    "    stop = '\\'' + stops[i] + '\\''\n",
    "    limit = 300000000\n",
    "    cam_id = 2\n",
    "    sqlquery = \"SELECT timestamp, frame_id, track_id, bee_id, x_pos_hive, y_pos_hive, orientation_hive FROM bb_detections_2016_stitched WHERE timestamp >  TIMESTAMP %s AND timestamp < TIMESTAMP %s AND cam_id = %d ORDER BY timestamp ASC LIMIT %d;\" % (start, stop, cam_id, limit)\n",
    "    data = getData(sqlquery)\n",
    "    #limit = 3000000\n",
    "    sqlquery = \"SELECT DISTINCT track_id FROM bb_detections_2016_stitched WHERE timestamp > TIMESTAMP %s AND timestamp < TIMESTAMP %s AND cam_id = %d ORDER BY track_id ASC LIMIT %d;\" % (start, stop, cam_id, limit)\n",
    "    track_ids = np.asarray(getData(sqlquery)).flatten().tolist()\n",
    "    xmax = 0.0\n",
    "    xmin = 1000.0\n",
    "    ymax = 0.0\n",
    "    ymin = 1000.0\n",
    "    for i,d in enumerate(data):\n",
    "        data[i, 0] = d[0].timestamp()\n",
    "        xmax = np.maximum(xmax, d[4])\n",
    "        xmin = np.minimum(xmin, d[4])\n",
    "        ymax = np.maximum(ymax, d[4])\n",
    "        ymin = np.minimum(ymin, d[4]) \n",
    "    print(\"xmax\", xmax)\n",
    "    print(\"xmin\", xmin)\n",
    "    print(\"ymax\", ymax)\n",
    "    print(\"ymin\", ymin)\n",
    "    borders=[[xmin-5,ymin-5], [xmax+5, ymax+5]]\n",
    "    df = pd.DataFrame(data, columns=['datetime', 'frame_id', 'track_id', 'bee_id', 'x', 'y', 'orientation'])\n",
    "    data = 0\n",
    "    history = OneStepBeeHistory(num_features, track_ids)\n",
    "    data_visual = []\n",
    "    start = time.time()\n",
    "    for i, tracks_t in enumerate(df.groupby('datetime')):\n",
    "        if i % 250 == 0 and i > 1:\n",
    "            print('Train data: {}/{}'.format(i, len(df.groupby('datetime'))))\n",
    "        dct = tracks_t[1]\n",
    "        positions = np.stack([dct.x, dct.y, dct.orientation, dct.datetime, dct.track_id, dct.bee_id], axis=1)\n",
    "        positions = np.append(positions, np.zeros((len(dct), bins_size)), axis=1)\n",
    "        neighbours= spatial.cKDTree(positions[:, :2]).query_ball_point(positions[:, :2], max_visual_range)\n",
    "        for j, pos in enumerate(positions):\n",
    "            history.save(pos[4], pos)\n",
    "        for j, pos in enumerate(positions):\n",
    "            if len(neighbours[j]) > 1:\n",
    "                # Filter out myself from neighbours\n",
    "                cur_neighbours = [x for x in neighbours[j] if x != j]\n",
    "                neighbour_positions = positions[cur_neighbours]\n",
    "                positions[j, 6:(num_features)] = getBeeSurroundings(pos, neighbour_positions, history, max_visual_range, num_bins = bee_vision_bins, borders = borders)\n",
    "        data_visual.append(positions)\n",
    "    data_visual = np.concatenate([x for x in data_visual])\n",
    "    end = time.time()\n",
    "    print(\"Time in seconds for Raycasting: \", end - start)\n",
    "    print(data_visual.shape)\n",
    "    df = pd.DataFrame(data_visual, columns=['x', 'y', 'orientation', 'datetime', 'track_id', 'bee_id'] + ['bee_vision_{}'.format(i) for i in range(bins_size)])\n",
    "    tracks = []\n",
    "    vision_bin_names = ['bee_vision_{}'.format(i) for i in range(bins_size)]\n",
    "    start = time.time()\n",
    "    for track in df.groupby('track_id'):\n",
    "        track = track[1].sort_values('datetime')\n",
    "        if len(track) > time_length:\n",
    "            orientation_diff_sin = list()\n",
    "            orientation_diff_cos = list()\n",
    "            track_dx = list()\n",
    "            track_dy = list()\n",
    "            track_dt = list()\n",
    "            tstep = datetime.datetime.utcfromtimestamp(track.datetime.values[0])\n",
    "            bee_id = bbids.BeesbookID(bbids.BeesbookID._dec_to_bin(track.bee_id.values[0]))\n",
    "            age = BeeMeta.get_age(bee_id, tstep).days + 1\n",
    "            if pd.isnull(age) or age < 1:\n",
    "                agenulls = agenulls + 1\n",
    "                continue\n",
    "            for i in range(1, len(track)):\n",
    "                value =  track.orientation.values[i] \n",
    "                orientation_diff_sin.append(np.sin(value))\n",
    "                orientation_diff_cos.append(np.cos(value))\n",
    "                difx =  track.x.values[i] - track.x.values[i-1]\n",
    "                dify =  track.y.values[i] - track.y.values[i-1]\n",
    "                track_dx.append(difx) #(dxt)\n",
    "                track_dy.append(dify) #(dyt)\n",
    "                dtime = (track.datetime.values[i]-track.datetime.values[i-1])\n",
    "                track_dt.append(dtime)\n",
    "            stacklen = track.x.values[1:].shape\n",
    "            values = np.stack([track.x.values[1:], track.y.values[1:], track.orientation.values[1:],\n",
    "                               track.datetime.values[1:], track.track_id.values[1:], track.bee_id.values[1:],\n",
    "                               np.ones(len(track_dt)) * age, np.zeros(stacklen), np.zeros(stacklen), np.zeros(stacklen),\n",
    "                               track_dt, track_dx, track_dy, orientation_diff_cos, orientation_diff_sin], axis=1).astype(np.float64)        \n",
    "            vision = track[vision_bin_names][1:].astype(np.float64)\n",
    "            tracks.append(np.concatenate((values, vision), axis=1))\n",
    "    end = time.time()\n",
    "    print(\"Time in seconds for deltas: \", end - start)\n",
    "    df = []\n",
    "    track = 0\n",
    "    vision = 0\n",
    "    data_visual = 0\n",
    "    start = time.time()\n",
    "    with tables.open_file(save_file_path, mode='a') as hdf5_file:\n",
    "        for track in tracks:\n",
    "            maxdxdy = np.argmax(np.abs(track[:, 11:13]), axis = 0)\n",
    "            if np.sum((np.linalg.norm(track[:, 11:13], axis= 1) > 25)) > 0:\n",
    "                print(\"Big jump in training data. Value: \", track[maxdxdy[0], 7], track[maxdxdy[1], 8])\n",
    "                print(\"Corrospending dts: \", track[maxdxdy[0], 6], track[maxdxdy[1], 6])\n",
    "                continue\n",
    "            dmov = np.sqrt(np.sum(np.abs(track[:, 7]))**2 + np.sum(np.abs(track[:, 8]))**2) / len(track)\n",
    "            track_movs.append(dmov)\n",
    "            for i in range(0, len(track)-time_length, 20):\n",
    "                hdf5_file.root.train.append(track[None, i: i+time_length-1])\n",
    "        end = time.time()\n",
    "        print(\"Time in seconds: \", end - start)\n",
    "        hdf5_file.close()\n",
    "print(\"Age was this often zero: \", agenulls)\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findFloats(listOfFloats, value):\n",
    "    for i, number in enumerate(listOfFloats):\n",
    "        if np.abs(float(number)-float(value)) < 0.00001:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random shuffle the training data on the hard disk, for large data sets, this takes ages\n",
    "import random\n",
    "import time\n",
    "import tables\n",
    "import numpy as np\n",
    "start = time.time()\n",
    "hdf5_file = tables.open_file('pathoffile.h5', mode='a')\n",
    "print(hdf5_file.root.train.shape)\n",
    "print(hdf5_file.root.train[0:10, :, :])\n",
    "random.shuffle(hdf5_file.root.train)\n",
    "print(hdf5_file.root.train.shape)\n",
    "print(hdf5_file.root.train[0:10, :, :])\n",
    "hdf5_file.close()\n",
    "end = time.time()\n",
    "hdf5_file.close()\n",
    "print(\"Time in seconds for shuffle: \", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network\n",
    "This part just shows some plots from part of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.autograd\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import tables \n",
    "from time import sleep\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert inputs.shape[0] == targets.shape[0]\n",
    "    if shuffle:\n",
    "        indices = np.arange(inputs.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, inputs.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def iterate_data(data, batchsize, shuffle=False):\n",
    "    if shuffle:\n",
    "        indices = np.arange(data.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, data.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield data[excerpt, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdf5_file = tables.open_file('pathoffile.h5', mode='r')\n",
    "train = hdf5_file.root.train[:10000]\n",
    "#The data is randomly shuffled. 50000 samples is enough to have representitive graphs for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdf5_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[20,0,:]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train shape:\n",
    "\n",
    "[track.x, track.y, track.orientation, \n",
    "track.datetime, track.track_id, track.bee_id,\n",
    "\n",
    "\n",
    "track_dt, track_dx, track_dy, \n",
    "orientation_diff_cos, orientation_diff_sin]    \n",
    "+ \n",
    "(bins_distance, bins_SINorientation, bins_COSorientation, bins_activity, bins_binary, bins_relativeOsin, bins_relativeOcos, borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = train[:, :-1, 10:].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_bins = 16\n",
    "# TODO: If bin_size changes the indicies below are wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary_values = X[:, :, 69:85].flatten()\n",
    "indicies = np.where(np.round(binary_values) == 1)\n",
    "print(indicies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dt\n",
    "plt.hist(np.abs(X[:, :, 0]).flatten(), 20)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dx\n",
    "fig = plt.hist(X[:, :, 1].flatten(), 50)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dy\n",
    "fig = plt.hist(X[:, :, 2].flatten(), 50)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#do\n",
    "fig = plt.hist(np.arctan2(X[:, :, 3], X[:, :, 4]).flatten(), 100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d sin\n",
    "fig = plt.hist(X[:, :, 3].flatten(), 100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cos\n",
    "plt.hist(X[:, :, 4].flatten(), 20)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.hist(X[:, :, 5].flatten(), 20)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Raycasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# distances\n",
    "fig = plt.hist(X[:, :, 5:21].flatten()[indicies], 100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# orientation in radian\n",
    "fig = plt.hist(np.arctan2(X[:, :, 21:37].flatten()[indicies], X[:, :, 37:53].flatten()[indicies]).flatten(), 100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sin\n",
    "fig = plt.hist(X[:, :, 21:37].flatten()[indicies], 100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cos\n",
    "fig = plt.hist(X[:, :, 37:53].flatten()[indicies], 100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#activity\n",
    "fig = plt.hist(X[:, :, 53:69].flatten()[indicies], 100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#binary\n",
    "fig = plt.hist(X[:, :, 69:85].flatten(), 100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# orientation relative in radian\n",
    "fig = plt.hist(np.arctan2(X[:, :, 85:101].flatten()[indicies], X[:, :, 101:117].flatten()[indicies]).flatten(), 100)\n",
    "#plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#orientation relative sin\n",
    "fig = plt.hist(X[:, :, 85:101].flatten()[indicies], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#orientation relative cos\n",
    "fig = plt.hist(X[:, :, 101:117].flatten()[indicies], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#borders\n",
    "fig = plt.hist(X[:, :, 117:133].flatten(), 100)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer Norm LSTM\n",
    "von Ben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Reshape(torch.nn.Module):\n",
    "    def __init__(self, outer_shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.outer_shape = outer_shape\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), *self.outer_shape)\n",
    "\n",
    "\n",
    "class LSTMWrapper(torch.nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(LSTMWrapper, self).__init__()\n",
    "        self.lstm = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_t = torch.rand(x.shape[1], self.lstm.hidden_size, dtype=x.dtype).to(x.device)\n",
    "        h_c = torch.rand(x.shape[1], self.lstm.hidden_size, dtype=x.dtype).to(x.device)\n",
    "\n",
    "        h_ts = []\n",
    "        h_cs = []\n",
    "        for i in range(x.shape[0]):\n",
    "            h_t, h_c = self.lstm(x[i].contiguous(), (h_t, h_c))\n",
    "            h_ts.append(h_t)\n",
    "            h_cs.append(h_c)\n",
    "\n",
    "        return torch.stack(h_ts), (torch.stack(h_ts), torch.stack(h_cs))\n",
    "\n",
    "\n",
    "class LayerNorm1D(nn.Module):\n",
    "\n",
    "    def __init__(self, num_outputs, eps=1e-5, affine=True):\n",
    "        super(LayerNorm1D, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(1, num_outputs))\n",
    "        self.bias = nn.Parameter(torch.zeros(1, num_outputs))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_mean = inputs.mean(1, keepdim=True).expand_as(inputs)\n",
    "        input_std = inputs.std(1, keepdim=True).expand_as(inputs)\n",
    "        x = (inputs - input_mean) / (input_std + self.eps)\n",
    "        return x * self.weight.expand_as(x) + self.bias.expand_as(x)\n",
    "\n",
    "\n",
    "class LayerNormLSTMCell(nn.LSTMCell):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super().__init__(input_size, hidden_size, bias)\n",
    "\n",
    "        self.ln_ih = nn.LayerNorm(4 * hidden_size)\n",
    "        self.ln_hh = nn.LayerNorm(4 * hidden_size)\n",
    "        self.ln_ho = nn.LayerNorm(hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        self.check_forward_input(input)\n",
    "        if hidden is None:\n",
    "            hx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
    "            cx = input.new_zeros(input.size(0), self.hidden_size, requires_grad=False)\n",
    "        else:\n",
    "            hx, cx = hidden\n",
    "        self.check_forward_hidden(input, hx, '[0]')\n",
    "        self.check_forward_hidden(input, cx, '[1]')\n",
    "\n",
    "        gates = self.ln_ih(F.linear(input, self.weight_ih, self.bias_ih)) \\\n",
    "                 + self.ln_hh(F.linear(hx, self.weight_hh, self.bias_hh))\n",
    "        i, f, o = gates[:, :(3 * self.hidden_size)].sigmoid().chunk(3, 1)\n",
    "        g = gates[:, (3 * self.hidden_size):].tanh()\n",
    "\n",
    "        cy = (f * cx) + (i * g)\n",
    "        hy = o * self.ln_ho(cy).tanh()\n",
    "        return hy, cy\n",
    "\n",
    "\n",
    "class LayerNormLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, bias=True, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        self.hidden0 = nn.ModuleList([\n",
    "            LayerNormLSTMCell(input_size=(input_size if layer == 0 else hidden_size * num_directions),\n",
    "                              hidden_size=hidden_size, bias=bias)\n",
    "            for layer in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        if self.bidirectional:\n",
    "            self.hidden1 = nn.ModuleList([\n",
    "                LayerNormLSTMCell(input_size=(input_size if layer == 0 else hidden_size * num_directions),\n",
    "                                  hidden_size=hidden_size, bias=bias)\n",
    "                for layer in range(num_layers)\n",
    "            ])\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        seq_len, batch_size, hidden_size = input.size()  # supports TxNxH only\n",
    "        num_directions = 2 if self.bidirectional else 1\n",
    "        if hidden is None:\n",
    "            hx = input.new_zeros(self.num_layers * num_directions, batch_size, self.hidden_size, requires_grad=False)\n",
    "            cx = input.new_zeros(self.num_layers * num_directions, batch_size, self.hidden_size, requires_grad=False)\n",
    "        else:\n",
    "            hx, cx = hidden\n",
    "\n",
    "        ht = [[None, ] * (self.num_layers * num_directions)] * seq_len\n",
    "        ct = [[None, ] * (self.num_layers * num_directions)] * seq_len\n",
    "\n",
    "        if self.bidirectional:\n",
    "            xs = input\n",
    "            for l, (layer0, layer1) in enumerate(zip(self.hidden0, self.hidden1)):\n",
    "                l0, l1 = 2 * l, 2 * l + 1\n",
    "                h0, c0, h1, c1 = hx[l0], cx[l0], hx[l1], cx[l1]\n",
    "                for t, (x0, x1) in enumerate(zip(xs, reversed(xs))):\n",
    "                    ht[t][l0], ct[t][l0] = layer0(x0, (h0, c0))\n",
    "                    h0, c0 = ht[t][l0], ct[t][l0]\n",
    "                    t = seq_len - 1 - t\n",
    "                    ht[t][l1], ct[t][l1] = layer1(x1, (h1, c1))\n",
    "                    h1, c1 = ht[t][l1], ct[t][l1]\n",
    "                xs = [torch.cat((h[l0], h[l1]), dim=1) for h in ht]\n",
    "            y  = torch.stack(xs)\n",
    "            hy = torch.stack(ht[-1])\n",
    "            cy = torch.stack(ct[-1])\n",
    "        else:\n",
    "            h, c = hx, cx\n",
    "            for t, x in enumerate(input):\n",
    "                for l, layer in enumerate(self.hidden0):\n",
    "                    ht[t][l], ct[t][l] = layer(x, (h[l], c[l]))\n",
    "                    x = ht[t][l]\n",
    "                h, c = ht[t], ct[t]\n",
    "            y  = torch.stack([h[-1] for h in ht])\n",
    "            hy = torch.stack(ht[-1])\n",
    "            cy = torch.stack(ct[-1])\n",
    "\n",
    "        return y, (hy, cy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Model Code\n",
    "von Ben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import weight_norm\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def log_sum_exp(x, dim=1):\n",
    "    x_max, x_argmax = x.max(dim, keepdim=True)\n",
    "    x_max_broadcast = x_max.expand(*x.size())\n",
    "    return x_max + torch.log(\n",
    "        torch.sum(torch.exp(x - x_max_broadcast), dim=dim, keepdim=True))\n",
    "\n",
    "class MDN(nn.Module):\n",
    "    \"\"\"A mixture density network layer\n",
    "    The input maps to the parameters of a MoG probability distribution, where\n",
    "    each Gaussian has O dimensions and diagonal covariance.\n",
    "    Arguments:\n",
    "        in_features (int): the number of dimensions in the input\n",
    "        out_features (int): the number of dimensions in the output\n",
    "        num_gaussians (int): the number of Gaussians per output dimensions\n",
    "    Input:\n",
    "        minibatch (BxD): B is the batch size and D is the number of input\n",
    "            dimensions.\n",
    "    Output:\n",
    "        (pi, sigma, mu) (BxG, BxGxO, BxGxO): B is the batch size, G is the\n",
    "            number of Gaussians, and O is the number of dimensions for each\n",
    "            Gaussian. Pi is a multinomial distribution of the Gaussians. Sigma\n",
    "            is the standard deviation of each Gaussian. Mu is the mean of each\n",
    "            Gaussian.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, num_gaussians):\n",
    "        super(MDN, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.num_gaussians = num_gaussians\n",
    "        self.pi = nn.Sequential(\n",
    "            nn.Linear(in_features, num_gaussians), nn.LogSoftmax(dim=1))\n",
    "        self.sigma = nn.Linear(in_features, out_features * num_gaussians)\n",
    "        self.mu = nn.Linear(in_features, out_features * num_gaussians)\n",
    "\n",
    "    def forward(self, minibatch):\n",
    "        pi = self.pi(minibatch)\n",
    "        sigma = self.sigma(minibatch)\n",
    "        # original sigma = torch.clamp(sigma, np.log(np.sqrt(1e-4)), 1e8)\n",
    "        # working \n",
    "        #sigma =  torch.clamp(sigma, np.log(np.sqrt(1e-3)), 5e1)\n",
    "        sigma = torch.clamp(sigma, np.log(np.sqrt(1e-4)), 1e4)\n",
    "        sigma = sigma.view(-1, self.num_gaussians, self.out_features)\n",
    "        mu = self.mu(minibatch)\n",
    "        mu = mu.view(-1, self.num_gaussians, self.out_features)\n",
    "        return pi, sigma, mu\n",
    "\n",
    "    @staticmethod\n",
    "    def gaussian_probability(sigma, x_mu, x):\n",
    "        \"\"\"Returns the probability of `data` given MoG parameters `sigma` and `mu`.\n",
    "        Arguments:\n",
    "            sigma (BxGxO): The standard deviation of the Gaussians. B is the batch\n",
    "                size, G is the number of Gaussians, and O is the number of\n",
    "                dimensions per Gaussian.\n",
    "            mu (BxGxO): The means of the Gaussians. B is the batch size, G is the\n",
    "                number of Gaussians, and O is the number of dimensions per Gaussian.\n",
    "            data (BxI): A batch of data. B is the batch size and I is the number of\n",
    "                input dimensions.\n",
    "        Returns:\n",
    "            probabilities (BxG): The probability of each point in the probability\n",
    "                of the distribution in the corresponding sigma/mu index.\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(1).expand_as(sigma)\n",
    "        var = (torch.exp(sigma)**2)\n",
    "        return -((x - x_mu)**2) / (2 * var + 1e-4) - sigma - math.log(\n",
    "            math.sqrt(2 * math.pi))\n",
    "\n",
    "    @staticmethod\n",
    "    def mdn_loss(pi, sigma, mu, target):\n",
    "        \"\"\"Calculates the error, given the MoG parameters and the target\n",
    "        The loss is the negative log likelihood of the data given the MoG\n",
    "        parameters.\n",
    "        \"\"\"\n",
    "        nll = log_sum_exp(pi[:, :, None] +\n",
    "                          MDN.gaussian_probability(sigma, mu, target))\n",
    "        nll = -torch.sum(nll, dim=-1)\n",
    "        return torch.mean(nll)\n",
    "\n",
    "    @staticmethod\n",
    "    def sample(pi, sigma, mu):\n",
    "        \"\"\"Draw samples from a MoG.\n",
    "        \"\"\"\n",
    "        categorical = Categorical(torch.exp(pi))\n",
    "        pis = list(categorical.sample().data)\n",
    "        sigma = torch.exp(sigma)\n",
    "        sample = Variable(\n",
    "            sigma.data.new(sigma.size(0), sigma.size(2)).normal_())\n",
    "        for i, idx in enumerate(pis):\n",
    "            sample[i] = sample[i].mul(sigma[i, idx]).add(mu[i, idx])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    if type(model) in [nn.Linear]:\n",
    "        nn.init.xavier_normal_(model.weight.data)\n",
    "    elif type(model) in [nn.LSTM, nn.RNN, nn.GRU]:\n",
    "        nn.init.xavier_normal_(model.weight_hh_l0)\n",
    "        nn.init.xavier_normal_(model.weight_ih_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "class SimpleRNN(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_outputs):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        # 32 was used for all the simulated data\n",
    "        #hidden_dim = 32 #\n",
    "        \n",
    "        hidden_dim = 128 #hidden_dim\n",
    "\n",
    "        #self.inp = torch.nn.Linear(n_features, hidden_size)\n",
    "        num_layers = 2\n",
    "        #self.rnn = LayerNormLSTM(n_features, hidden_dim, num_layers = num_layers)\n",
    "        self.rnn = torch.nn.LSTM(n_features, hidden_dim, num_layers = num_layers)\n",
    "        \n",
    "        # 64 was used for all the simulated data\n",
    "        #self.out = torch.nn.Linear(hidden_dim, 64)\n",
    "        \n",
    "        #self.out = torch.nn.Linear(hidden_dim, 32)\n",
    "        self.mdn = MDN(hidden_dim, n_outputs, 5)\n",
    "\n",
    "        \n",
    "        #self.hidden = None\n",
    "        \n",
    "        initialize_weights(self.rnn)\n",
    "        #initialize_weights(self.out)\n",
    "        initialize_weights(self.mdn)\n",
    "\n",
    "    def step(self, inputs, hidden=None, verbose=False):\n",
    "        #input = self.inp(input)\n",
    "        if verbose:\n",
    "            print(\"Step 0:\")\n",
    "            print(inputs.shape)\n",
    "        inputs = inputs.permute([1, 0, 2])\n",
    "        if verbose:\n",
    "            print(\"Step 1:\")\n",
    "            print(inputs.shape)\n",
    "        #self.rnn.flatten_parameters()\n",
    "        output, hidden = self.rnn(inputs, hidden)\n",
    "        output = output[-1, :, :] #output[:, :, :] #output[-1, :, :]\n",
    "        #output = output.permute([1, 0, 2])\n",
    "        if verbose:\n",
    "            print(\"Step 3:\")\n",
    "            print(output.shape)\n",
    "        output = output.squeeze()\n",
    "        if verbose:\n",
    "            print(\"Step 4:\")\n",
    "            print(output.shape)\n",
    "        #output = self.out(output)\n",
    "        if verbose:\n",
    "            print(\"Step 5:\")\n",
    "            print(output.shape)\n",
    "            print(output)\n",
    "        output = self.mdn(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def forward(self, inputs, hidden=None, verbose=False):\n",
    "        if verbose:\n",
    "            print(\"inputs size: \", inputs.size)\n",
    "        batch_size = inputs.size(0)    \n",
    "        output, hidden = self.step(inputs, hidden, verbose=verbose)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "\n",
    "class BeeRNN(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_outputs):\n",
    "        super(BeeRNN, self).__init__()\n",
    "        # 32 was used for all the simulated data\n",
    "        #hidden_dim = 32 #\n",
    "        \n",
    "        hidden_dim = 32 #hidden_dim\n",
    "\n",
    "        #self.inp = torch.nn.Linear(n_features, hidden_size)\n",
    "        num_layers = 1\n",
    "        #self.rnn = LayerNormLSTM(n_features, hidden_dim, num_layers = num_layers)\n",
    "        self.rnn = torch.nn.LSTM(n_features, hidden_dim, num_layers = num_layers)\n",
    "        self.out = torch.nn.Linear(hidden_dim, 64) # 64\n",
    "        self.mdn = MDN(64, n_outputs, 5)\n",
    "        \n",
    "        initialize_weights(self.rnn)\n",
    "        initialize_weights(self.out)\n",
    "        initialize_weights(self.mdn)\n",
    "\n",
    "    def step(self, inputs, hidden=None, verbose=False):\n",
    "        #input = self.inp(input)\n",
    "        if verbose:\n",
    "            print(\"Step 0:\")\n",
    "            print(inputs.shape)\n",
    "        inputs = inputs.permute([1, 0, 2])\n",
    "        if verbose:\n",
    "            print(\"Step 1:\")\n",
    "            print(inputs.shape)\n",
    "        #self.rnn.flatten_parameters()\n",
    "        output, hidden = self.rnn(inputs, hidden)\n",
    "        output = output[-1, :, :] #output[:, :, :] #output[-1, :, :]\n",
    "        #output = output.permute([1, 0, 2])\n",
    "        if verbose:\n",
    "            print(\"Step 3:\")\n",
    "            print(output.shape)\n",
    "        output = output.squeeze()\n",
    "        if verbose:\n",
    "            print(\"Step 4:\")\n",
    "            print(output.shape)\n",
    "        output = self.out(output)\n",
    "        if verbose:\n",
    "            print(\"Step 5:\")\n",
    "            print(output.shape)\n",
    "            print(output)\n",
    "        output = self.mdn(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def forward(self, inputs, hidden=None, verbose=False):\n",
    "        if verbose:\n",
    "            print(\"inputs size: \", inputs.size)\n",
    "        batch_size = inputs.size(0)    \n",
    "        output, hidden = self.step(inputs, hidden, verbose=verbose)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "\n",
    "        return validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mselosses(pi, mu, target):\n",
    "    pis = torch.exp(pi)/ torch.sum(torch.exp(pi), dim = 1)[:, None].expand(-1, 1)\n",
    "    Y = torch.sum((pis[:,:,None] * mu)[:, :, :], dim = 1)\n",
    "    return torch.sum((Y[:, :2]-target[:, :2])**2)/target.shape[0]\n",
    "    #return ((Y[:, :2]-target[:, :2])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def anglediffs(pi, mu, target):\n",
    "    pis = torch.exp(pi)/ torch.sum(torch.exp(pi), dim = 1)[:, None].expand(-1, 1)\n",
    "    Y = torch.sum((pis[:,:,None] * mu)[:, :, :], dim = 1)\n",
    "    n1 = torch.norm(Y[:, 2:], dim = 1)\n",
    "    n2 = torch.norm(target[:, 2:], dim = 1) \n",
    "    cosa = (torch.sum(target[:, 2:] * Y[:, 2:], dim = 1)) / (n1 * n2)\n",
    "    return torch.sum(torch.acos(cosa))/target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeanSample(pi, sigma, mu):\n",
    "    pis = torch.exp(pi)/ torch.sum(torch.exp(pi), dim = 1)[:, None].expand(-1, 5)\n",
    "    Y = torch.sum((pis[:,:,None] * mu)[:, :, :], dim = 1)\n",
    "    return Y[:, :]\n",
    "    #return ((Y[:, :2]-target[:, :2])**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vision_bins = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "constrnn = SimpleRNN(n_features=5 + (vision_bins * 8), n_outputs=4).cuda()\n",
    "optimizer_const = torch.optim.RMSprop(constrnn.parameters(), lr=0.0001)\n",
    "running_loss_const = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rnn = SimpleRNN(n_features=5 +(vision_bins * 8), n_outputs=4).cuda()\n",
    "optimizer = torch.optim.RMSprop(rnn.parameters(), lr=0.0001)\n",
    "running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = BeeRNN(n_features=5 +(vision_bins * 8), n_outputs=4).cuda()\n",
    "rnn = torch.load('beernn.pt')\n",
    "optimizer = torch.optim.RMSprop(rnn.parameters(), lr=0.001)\n",
    "running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constrnn = BeeRNN(n_features=5 + (vision_bins * 8), n_outputs=4).cuda()\n",
    "optimizer_const = torch.optim.RMSprop(constrnn.parameters(), lr=0.001)\n",
    "running_loss_const = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(rnn.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec_losses = []  \n",
    "rec_losses_const = []\n",
    "mse_diffs = []\n",
    "mse_diffs_const = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_X = [] \n",
    "batch_Y = [] \n",
    "tqdm_iter = [] \n",
    "minibatch_idx = [] \n",
    "batch_data = []  \n",
    "loss = []  \n",
    "mse_diffs = []  \n",
    "batch_X_const = []  \n",
    "batch_Y_const = []  \n",
    "rec_losses_test_const = []\n",
    "rec_losses_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trains normal and constant network\n",
    "import torch\n",
    "from torch import autograd\n",
    "from random import randint\n",
    "\n",
    "# Training\n",
    "tqdm_epochs = tqdm_notebook(list(range(3)))\n",
    "rec_losses = []  \n",
    "rec_losses_const = []\n",
    "batch_size = 32\n",
    "loss_step = 100\n",
    "i = 0\n",
    "testinterval = 100#100\n",
    "\n",
    "mse_diffs = []\n",
    "mse_diffs_test = []\n",
    "mse_diffs_const = []\n",
    "test_rnn_const = []\n",
    "test_rnn = []\n",
    "h5ftrain = tables.open_file('pathtofile.h5', mode='r')\n",
    "h5ftest = tables.open_file('pathtofile.h5', mode='r')\n",
    "train = h5ftrain.root.train\n",
    "test = h5ftest.root.train[:15000] \n",
    "print(\"trainshape: \", train.shape)\n",
    "print(\"testshape: \", test.shape)\n",
    "ci = 0\n",
    "constant_stop = 200000000000000000000\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "for epoch in tqdm_epochs:    \n",
    "    tqdm_iter = tqdm.tqdm_notebook(enumerate(iterate_data(train , batchsize=batch_size, shuffle=False)),\n",
    "                                   total=train.shape[0] // batch_size)\n",
    "    for minibatch_idx, (batch_data) in tqdm_iter: \n",
    "        batch_X = batch_data[:, :-1, 6+4:].astype(np.float32)\n",
    "        i = i+1\n",
    "        batch_Y = batch_data[:, -1, (1+6+4):(5+6+4)].astype(np.float32)\n",
    "        with autograd.detect_anomaly():\n",
    "            rnn.zero_grad()\n",
    "            batch_X = torch.autograd.Variable(torch.from_numpy(batch_X)).cuda()\n",
    "            batch_Y = torch.autograd.Variable(torch.from_numpy(batch_Y).float()).cuda()\n",
    "            Y_predicted, hidden = rnn.forward(batch_X, verbose=False) #847\n",
    "            pi, sigma, mu = Y_predicted\n",
    "            loss = MDN.mdn_loss(pi, sigma, mu, batch_Y).cuda()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            rec_losses.append(float(loss.cpu().data.numpy()))\n",
    "            mse_diffs.append(mselosses(pi, mu, batch_Y).cpu().data.numpy())\n",
    "            tqdm_epochs.set_description(\"Loss {:6.5f}\".format( np.mean(rec_losses[-100:])))\n",
    "        if i == testinterval:\n",
    "            i = 0\n",
    "            rec_losses_test_const = []\n",
    "            rec_losses_test = []\n",
    "            mse_diffs_testintervall = []\n",
    "            for batch_data in iterate_data(test[:10000] , batchsize=batch_size, shuffle=False):\n",
    "                rnn.zero_grad()\n",
    "                batch_X = batch_data[:, :-1, 6+4:].astype(np.float32)\n",
    "                batch_Y = batch_data[:, -1, (1+6+4):(5+6+4)].astype(np.float32)\n",
    "                batch_X = torch.from_numpy(batch_X)\n",
    "                batch_X = torch.autograd.Variable(batch_X).cuda()\n",
    "                batch_X_const = torch.from_numpy(np.zeros(batch_X.shape).astype(np.float32))\n",
    "                batch_X_const = torch.autograd.Variable(batch_X_const).cuda()\n",
    "                batch_Y = torch.from_numpy(batch_Y)\n",
    "                batch_Y = torch.autograd.Variable(batch_Y.float()).cuda()\n",
    "                Y_predicted, hidden = rnn.forward(batch_X, verbose=False)\n",
    "                pi, sigma, mu = Y_predicted\n",
    "                loss = MDN.mdn_loss(pi, sigma, mu, batch_Y) \n",
    "                mse_diffs_testintervall.append(mselosses(pi, mu, batch_Y).cpu().data.numpy())\n",
    "                rec_losses_test.append(np.mean(float(loss.cpu().data.numpy())))\n",
    "            mse_diffs_test.append(np.mean(mse_diffs_testintervall))\n",
    "            test_rnn.append(np.mean(rec_losses_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5ftrain.close()\n",
    "h5ftest.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16,4))\n",
    "ax.plot(pd.Series(rec_losses).rolling(1).mean())\n",
    "\n",
    "plt.xlabel('Training batches')\n",
    "plt.ylabel('MDN Loss')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16,4))\n",
    "ax.plot(pd.Series(test_rnn).rolling(1).mean())\n",
    "plt.xlabel('Test batches')\n",
    "plt.ylabel('MDN Loss')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16,4))\n",
    "ax.plot(pd.Series(mse_diffs).rolling(1).mean())\n",
    "plt.xlabel('Train batches')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(16,4))\n",
    "ax.plot(pd.Series(mse_diffs_test).rolling(1).mean())\n",
    "plt.xlabel('Test batches')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "\n",
    "orientierung der Biene visualisieren "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "from graphics import *\n",
    "import random\n",
    "\n",
    "from datetime import timedelta, datetime, date\n",
    "from scipy import spatial\n",
    "\n",
    "from simulationhelpers import *\n",
    "\n",
    "import time\n",
    "import psycopg2\n",
    "import psycopg2.extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "connect_str = \"\"\"dbname='beesbook' user='mehmed' host='localhost' password='bbvision' application_name='memel'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with psycopg2.connect(connect_str) as conn:\n",
    "    with conn.cursor('db_cursor', cursor_factory=psycopg2.extras.DictCursor) as cur:\n",
    "        cur.execute(\"\"\"SELECT timestamp, track_id, bee_id, x_pos_hive, y_pos_hive, orientation_hive, cam_id\n",
    "        FROM bb_detections_2016_stitched\n",
    "        WHERE timestamp > TIMESTAMP '2016-07-20 14:00:00' AND timestamp < TIMESTAMP '2016-07-20 14:05:00'\n",
    "        AND (cam_id = 0)\n",
    "        ORDER BY timestamp ASC LIMIT %(limit)s;\"\"\", {'limit': 500000})          \n",
    "        rows = cur.fetchall()\n",
    "#AND (cam_id = 0 OR cam_id = 1)\n",
    "print(len(rows))\n",
    "end = time.time()\n",
    "print(\"Time in seconds: \", end - start)\n",
    "\n",
    "\n",
    "data = np.asarray(rows)\n",
    "rows = 0\n",
    "print(\"Data shape: \", data.shape)\n",
    "\n",
    "for i,d in enumerate(data):\n",
    "    data[i, 0] = d[0].timestamp()\n",
    "print(data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, columns=['datetime', 'track_id', 'bee_id', 'x', 'y', 'orientation', 'cam_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "with psycopg2.connect(connect_str) as conn:\n",
    "    with conn.cursor('db_cursor', cursor_factory=psycopg2.extras.DictCursor) as cur:\n",
    "        cur.execute(\"\"\"SELECT DISTINCT track_id\n",
    "        FROM bb_detections_2016_stitched\n",
    "        WHERE timestamp > TIMESTAMP '2016-07-20 14:00:00' AND timestamp < TIMESTAMP '2016-07-20 14:05:00'\n",
    "        AND (cam_id = 0)\n",
    "        ORDER BY track_id ASC LIMIT %(limit)s;\"\"\", {'limit': 500000})          \n",
    "        track_ids = cur.fetchall()\n",
    "#AND (cam_id = 0 OR cam_id = 1)\n",
    "print(len(track_ids))\n",
    "end = time.time()\n",
    "print(\"Time in seconds: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_ids = np.asarray(track_ids).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "track_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "10906746571586957921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: put the smallest value around 0, 0\n",
    "num_agents = len(track_ids)\n",
    "print(\"Number of agents: \", num_agents)\n",
    "num_timestamps = df.groupby('datetime').nunique().shape[0]\n",
    "print(\"Number of timesteps: \", num_timestamps)\n",
    "num_features = 3\n",
    "historys = np.ones(((len(track_ids), num_timestamps, num_features))) * (-1000)\n",
    "timestamp = 0\n",
    "for dataframes in df.groupby('datetime'):\n",
    "    for index, row in dataframes[1].iterrows():\n",
    "        bee_index = track_ids.index(row['track_id'])\n",
    "        #oldX = historys[bee_index, timestamp-1,0]\n",
    "        #oldY = historys[bee_index, timestamp-1,1]     \n",
    "        x = row['x']\n",
    "        y = row['y']\n",
    "        o = row['orientation']\n",
    "        #if (timestamp > 0) and ((oldX < 0 and oldY < 0) or ((abs(oldX-x) > 500) or (abs(oldY-y) > 500))):\n",
    "        #    continue\n",
    "        historys[bee_index, timestamp,:] = x, y, o\n",
    "    timestamp = timestamp + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initarray = np.ones(((len(track_ids), num_features))) * (-1000)\n",
    "a = 0\n",
    "for i in range(0, historys.shape[0]):\n",
    "    for j in range(0, num_timestamps):\n",
    "        if historys[i, j, 0] > - 999:\n",
    "            initarray[i, :] = historys[i, j, :]\n",
    "            a = a + 1\n",
    "            break\n",
    "print(len(track_ids))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(initarray[:, 0] > -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historys[initarray[:, 0] > -999, :5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in initarray[initarray[:, 0] > -999]:\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Bee:\n",
    "    def __init__(self, N, pos, color, velo, bee_id, vision_bins, o = 0):\n",
    "        self.point = Circle(Point(pos[0],pos[1]),10)\n",
    "        self.visionpoint = Circle(Point(pos[0],pos[1]),50)\n",
    "        self.line = Line(self.point.getCenter(), self.point.getCenter())\n",
    "        self.oldPos = np.array([pos[0], pos[1]])\n",
    "        self.point.setFill(color)\n",
    "        self.history = []\n",
    "        self.velo = velo\n",
    "        self.id = bee_id\n",
    "        self.vision = np.zeros(vision_bins*8)\n",
    "        self.t = 0\n",
    "        self.orientation = o\n",
    "        self.oldOrientation = o\n",
    "        self.xO = np.cos(o)\n",
    "        self.yO = np.sin(o)\n",
    "        self.dO = 0\n",
    "        self.gotMoved = False\n",
    "        self.headingVec = Line(self.point.getCenter(), self.point.getCenter()) \n",
    "        self.vlines = []\n",
    "        self.label = np.zeros((4))\n",
    "        for i in range(0, vision_bins+1):\n",
    "            self.vlines.append(Line(self.point.getCenter(), Point(0, 0)))\n",
    "        self.wlines = []\n",
    "        for i in range(0, vision_bins):\n",
    "            self.wlines.append(Line(self.point.getCenter(), Point(0, 0))) \n",
    "        self.opinion = np.random.uniform(-1, 1)\n",
    "        self.uncertainty = np.random.uniform(0, 0.5)\n",
    "        self.conv = np.random.uniform(0.1, 0.4)\n",
    "        self.future_vs = np.zeros(40)\n",
    "        self.velospeed = 1\n",
    "        self.neighbours = np.zeros(N) #TODO: \n",
    "        self.neighbourocc = []\n",
    "        self.repulsion_time = 0\n",
    "\n",
    "    def getX(self): \n",
    "        return self.point.getCenter().getX()\n",
    "\n",
    "    def getY(self):\n",
    "        return self.point.getCenter().getY()\n",
    "\n",
    "    def getPos(self):\n",
    "        return np.array([self.getX(), self.getY()])\n",
    "\n",
    "    def setColor(self,color):\n",
    "        self.point.setFill(color)\n",
    "        \n",
    "    def getT(self): \n",
    "        return self.t\n",
    "    \n",
    "    def incT(self): \n",
    "        self.t = self.t + 0.33\n",
    "        return self.t\n",
    "    \n",
    "    def setOrientation(self, xO, yO):\n",
    "        self.oldOrientation = self.orientation\n",
    "        o = np.arctan2(xO, yO)\n",
    "        self.dO = angle_between_rad(o, self.orientation)\n",
    "        self.xO = xO\n",
    "        self.yO = yO\n",
    "        self.orientation = o\n",
    "            \n",
    "    def setOrientationO(self, o):\n",
    "        self.oldOrientation = self.orientation\n",
    "        self.dO = angle_between_rad(o, self.orientation)\n",
    "        self.orientation = o\n",
    "        self.xO = np.sin(o)\n",
    "        self.yO = np.cos(o)\n",
    "        \n",
    "    def getCurrState(self, vision_bins):\n",
    "        mo = angle_between_rad_vec(self.orientation, self.velo)\n",
    "        #array = np.array([self.getX(), self.getY(), self.orientation, self.getT(), self.id, np.sin(mo), np.cos(mo)])\n",
    "        array = np.array([self.getX(), self.getY(), self.orientation, self.getT(), self.id, np.sin(mo), np.cos(mo)])\n",
    "        return np.concatenate([array, self.vision])\n",
    "\n",
    "    \n",
    "    def appendTimestep(self, OSHistory, vision_bins):\n",
    "        dx, dy = self.velo[0], self.velo[1]\n",
    "        dxt, dyt = transformCordinateSystem(self.oldOrientation, dx, dy)\n",
    "        array = np.array([self.getX(), self.getY(), self.orientation, np.sum(self.neighbours > 0), self.velospeed, len(self.neighbourocc), \n",
    "                          0, dx, dy, np.cos(self.orientation), np.sin(self.orientation)])\n",
    "        self.history.append(np.concatenate([np.concatenate([self.label, array]), self.vision]))\n",
    "\n",
    "\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Bee ID = \" + self.id.__str__() + \"velo = \" + self.velo.__str__()  + \"; position = (\" + self.point.getCenter().getX().__str__() + \", \" + self.point.getCenter().getY().__str__() + \")\" + \"; orientation = (\" + self.orientation.__str__()\n",
    "\n",
    "def initialize(num_agents, window, winWidth, winHeight, vision_bins, draw, algorithm):\n",
    "    global agents\n",
    "    agents = []\n",
    "    bee_id = 0\n",
    "    c = getDistinctColors(num_agents)\n",
    "    # Random init\n",
    "    if algorithm == 0 or algorithm == 1 or algorithm == 2 or algorithm == 4 or algorithm == 5 or algorithm == 6:\n",
    "        for i in range(num_agents):\n",
    "            agents.append(Bee(num_agents, np.array([np.random.uniform(0, winWidth), np.random.uniform(0, winHeight)])\n",
    "                              ,color_rgb(c[bee_id][0]\n",
    "                                         ,c[bee_id][1],c[bee_id][2]), np.zeros(2), bee_id, vision_bins))\n",
    "            bee_id = bee_id + 1\n",
    "    elif algorithm == 9:\n",
    "        for i in range(num_agents):\n",
    "            agents.append(Bee(num_agents, np.array([initarray[bee_id, 0], initarray[bee_id, 1]]),color_rgb(c[bee_id][0],c[bee_id][1],c[bee_id][2]), np.zeros(2), bee_id, vision_bins))\n",
    "            bee_id = bee_id + 1\n",
    "    elif algorithm == 3:\n",
    "        x = windows_data[0, 0] #winWidth/2\n",
    "        y = windows_data[0, 1] #winHeight/2\n",
    "        o = windows_data[0, 2]\n",
    "        agents.append(Bee(num_agents, np.array([x, y]),color_rgb(c[bee_id][0],c[bee_id][1],c[bee_id][2]),\n",
    "                            np.zeros(2), bee_id, vision_bins, o))\n",
    "    else:\n",
    "        for i in range(num_agents):\n",
    "            agents.append(Bee(num_agents, np.array([initarray[bee_id, 0], initarray[bee_id, 1]]),color_rgb(c[bee_id][0],c[bee_id][1],c[bee_id][2]), np.zeros(2), bee_id, vision_bins))\n",
    "            bee_id = bee_id + 1\n",
    "    draw_agents(window, draw)\n",
    "\n",
    "    \n",
    "def draw_agents(window, draw):\n",
    "    \"\"\"Draw all agents into window\"\"\"\n",
    "    if draw == True:\n",
    "        for ai in agents:\n",
    "            ai.point.undraw()\n",
    "            ai.point.draw(window)\n",
    "            n_distincts = min(np.sum(ai.neighbours > 0), 4)/4.0\n",
    "            ai.point.setFill(color_rgb(255, int(round(255-(n_distincts * 255))),0))\n",
    "\n",
    "                \n",
    "def move_agent(aj, window, draw, algoirthm = -1):\n",
    "    \"\"\"Move agent according to agent.velo\"\"\"\n",
    "    #Movement\n",
    "    aj.oldPos = np.array([aj.getX(), aj.getY()])\n",
    "    aj.point.move(aj.velo[0],aj.velo[1]) \n",
    "    if draw == True:\n",
    "        aj.line.undraw() \n",
    "    aj.line = Line(aj.point.getCenter(), Point(aj.getX() + aj.yO, aj.getY() + aj.xO))\n",
    "    if draw == True:\n",
    "        if algorithm == 5 or algorithm == 6:\n",
    "            n_distincts = min(np.sum(aj.neighbours > 0), 4)/4.0\n",
    "            aj.point.setFill(color_rgb(255, int(round(255-(n_distincts * 255))),0))\n",
    "        aj.line.setFill(\"black\")\n",
    "        aj.line.setArrow(\"last\")\n",
    "        aj.line.draw(window)\n",
    "    aj.headingVec = Line(Point(aj.oldPos[0], aj.oldPos[1]), aj.point.getCenter())\n",
    "    if draw == True:\n",
    "        aj.headingVec.draw(window)\n",
    "\n",
    "###################################### Movement Models ######################################\n",
    "# takes the steps from historys\n",
    "def real_step(aj, agents, window):\n",
    "    new_pos = historys[aj.id, timestep, :]\n",
    "    m = np.array([0, 0])\n",
    "    aj.point.undraw()\n",
    "    aj.gotMoved = False\n",
    "    if new_pos[0] > -999 or new_pos[1] > -999:\n",
    "        m = new_pos[:2] - [aj.getX(), aj.getY()]\n",
    "        aj.setOrientation(np.cos(new_pos[2]), np.sin(new_pos[2]))\n",
    "        aj.point.draw(window)\n",
    "        aj.gotMoved = True\n",
    "    aj.velo = m\n",
    "\n",
    "    \n",
    "# takes the steps from window_data\n",
    "def window_step(aj):\n",
    "    w = windows_data[timestep+1, 6:]\n",
    "    Y = w[1:5]\n",
    "    dx = Y[0]\n",
    "    dy = Y[1]\n",
    "    dxt, dyt = dx, dy\n",
    "    aj.velo = np.array([dxt, dyt])  \n",
    "    newOrientation = np.arctan2(Y[3], Y[2]) \n",
    "    if newOrientation > np.pi:\n",
    "        newOrientation = - np.pi + (newOrientation - np.pi)\n",
    "    if newOrientation < -np.pi:\n",
    "        newOrientation =  np.pi - (- np.pi - newOrientation)\n",
    "    aj.setOrientationO(newOrientation)  \n",
    "\n",
    "    \n",
    "# random walk    \n",
    "def simple_step(aj, agents):\n",
    "        m = np.array([(-1)**random.randint(0,1) * random.uniform(0,2.5), (-1)**random.randint(0,1) * random.uniform(0,2.5)])\n",
    "        aj.velo = m\n",
    "        o = np.arctan2(aj.velo[0], aj.velo[1])\n",
    "        aj.setOrientationO(o)\n",
    "\n",
    "# Super Simple Model\n",
    "def constant_step(aj, agents, winWidth, winHeight, max_visual_range):\n",
    "    label = np.zeros((4))\n",
    "    posX = aj.point.getCenter().getX()\n",
    "    posY = aj.point.getCenter().getY()\n",
    "    m = aj.velo\n",
    "    m = normalize(m, 1)\n",
    "    o = np.arctan2(m[1], m[0])\n",
    "    if posX - max_visual_range < 0:\n",
    "        d = 0.0 - (posX - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        m[0] = m[0] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posX + max_visual_range > winWidth:\n",
    "        d = (posX + max_visual_range) - winWidth\n",
    "        wd = d/max_visual_range\n",
    "        m[0] = m[0] + wd * -1\n",
    "        label[3] = 1\n",
    "    if posY - max_visual_range < 0:\n",
    "        d = 0.0 - (posY - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        m[1] = m[1] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posY + max_visual_range > winHeight:\n",
    "        d = (posY + max_visual_range) - winHeight\n",
    "        wd = d/max_visual_range\n",
    "        m[1] = m[1] + wd * -1\n",
    "        label[3] = 1\n",
    "    o = np.arctan2(m[1], m[0])\n",
    "    aj.label = label\n",
    "    return m, o\n",
    "    \n",
    "def complex_model(aj, agents, winWidth, winHeight, max_visual_range):\n",
    "    posX = aj.point.getCenter().getX()\n",
    "    posY = aj.point.getCenter().getY()\n",
    "    label = np.zeros((4))\n",
    "    w = 0.2\n",
    "    ai, dist = find_nearest_neighbor(aj, agents)\n",
    "    m = aj.velo\n",
    "    max_visual_range = max_visual_range - 5\n",
    "    if dist < 10:\n",
    "        ma = np.array([posX - ai.getX(), posY - ai.getY()])\n",
    "        m = m + 0.01 * ma\n",
    "        label[2] = 1\n",
    "    elif dist < max_visual_range:\n",
    "        m = m + w*np.array([ai.velo[0], ai.velo[1]])\n",
    "        label[1] = 1\n",
    "    m = normalize(m, 1)\n",
    "    if posX - max_visual_range < 0:\n",
    "        d = 0.0 - (posX - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        m[0] = m[0] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posX + max_visual_range > winWidth:\n",
    "        d = (posX + max_visual_range) - winWidth\n",
    "        wd = d/max_visual_range\n",
    "        m[0] = m[0] + wd * -1\n",
    "        label[3] = 1\n",
    "    if posY - max_visual_range < 0:\n",
    "        d = 0.0 - (posY - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        m[1] = m[1] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posY + max_visual_range > winHeight:\n",
    "        d = (posY + max_visual_range) - winHeight\n",
    "        wd = d/max_visual_range\n",
    "        m[1] = m[1] + wd * -1\n",
    "        label[3] = 1\n",
    "    if np.sum(label) <= 0:\n",
    "        label[0] = 1\n",
    "    o = np.arctan2(m[1], m[0])\n",
    "    aj.label = label \n",
    "    return m, o\n",
    "\n",
    "\n",
    "\n",
    "def social_model(aj, agents, winWidth, winHeight, max_visual_range):\n",
    "    posX = aj.point.getCenter().getX()\n",
    "    posY = aj.point.getCenter().getY()\n",
    "    label = 0\n",
    "    w = 0.2\n",
    "    ai, dist = find_nearest_neighbor(aj, agents)\n",
    "    m = aj.velo\n",
    "    if dist < max_visual_range:\n",
    "        opinionDiff = abs(ai.opinion - aj.opinion)\n",
    "        if (opinionDiff < aj.uncertainty):\n",
    "            m = m + w*np.array([ai.velo[0], ai.velo[1]])\n",
    "            #print(\"asdf\")\n",
    "            #print(opinionDiff)\n",
    "            #print(aj.opinion)\n",
    "            aj.opinion = aj.opinion + aj.conv * (ai.opinion - aj.opinion)\n",
    "            #print(aj.opinion)\n",
    "    if dist < 25:\n",
    "        ma = np.array([posX - ai.getX(), posY - ai.getY()])\n",
    "        m = m + 0.01 * ma\n",
    "        label = 2\n",
    "    m = normalize(m, 1)\n",
    "    if posX - max_visual_range <= 0:\n",
    "        d = 0.0 - (posX - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        m[0] = m[0] + wd * 1\n",
    "        label = 3\n",
    "    if posX + max_visual_range >= winWidth:\n",
    "        d = (posX + max_visual_range) - winWidth\n",
    "        wd = d/max_visual_range\n",
    "        m[0] = m[0] + wd * -1\n",
    "        label = 4\n",
    "    if posY - max_visual_range <= 0:\n",
    "        d = 0.0 - (posY - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        m[1] = m[1] + wd * 1\n",
    "        label = 5\n",
    "    if posY + max_visual_range >= winHeight:\n",
    "        d = (posY + max_visual_range) - winHeight\n",
    "        wd = d/max_visual_range\n",
    "        m[1] = m[1] + wd * -1\n",
    "        label = 6\n",
    "    o = np.arctan2(m[1], m[0])\n",
    "    aj.label = label \n",
    "    #aj.velo = m\n",
    "    #aj.setOrientationO(o)\n",
    "    return m, o\n",
    "\n",
    "def find_neighbors_zoi(aj, zor_r, zoo_r, zoa_r, agents): \n",
    "    \"\"\"K-nearest neighbor function for agents.\"\"\"\n",
    "    distances = [np.linalg.norm(np.array([aj.point.getCenter().getX(), aj.point.getCenter().getY()]) -\n",
    "                                np.array([ai.point.getCenter().getX(), ai.point.getCenter().getY()])) for ai in agents]\n",
    "    sorted_distances = np.sort(distances)\n",
    "    nr = []\n",
    "    no = []\n",
    "    na = []\n",
    "    for x in sorted_distances[1:]:\n",
    "        if x <= zor_r:\n",
    "            nr.append(agents[distances.index(x)])\n",
    "        elif x <= zoo_r:\n",
    "            no.append(agents[distances.index(x)])\n",
    "        elif x <= zoa_r:\n",
    "            na.append(agents[distances.index(x)])\n",
    "        else:\n",
    "            break\n",
    "    return (nr, no, na)\n",
    "\n",
    "def add_noise(vec, noise=2):\n",
    "    \"\"\"\n",
    "    add noise to the vector\n",
    "    \"\"\"\n",
    "    if noise == 0:\n",
    "        return vec\n",
    "    norm = np.linalg.norm(vec)\n",
    "    random_angle = (np.random.rand()-0.5)*2*noise\n",
    "    random_angle = np.radians(random_angle)\n",
    "    vec_new = turn_vector(vec, random_angle)\n",
    "    vec_new = normalize(vec_new, norm)\n",
    "    return vec_new\n",
    "\n",
    "# Couzin model\n",
    "def couzin(aj, agents, winWidth, winHeight, max_visual_range):\n",
    "    zor_r = 15\n",
    "    zoo_r = 35\n",
    "    zoa_r = 45\n",
    "    max_visual_range = max_visual_range - 5\n",
    "    m = aj.velo\n",
    "    posX = aj.point.getCenter().getX()\n",
    "    posY = aj.point.getCenter().getY()\n",
    "    label = np.zeros((4))\n",
    "    nr, no, na = find_neighbors_zoi(aj, zor_r, zoo_r, zoa_r, agents)\n",
    "    ds = np.array([0.0, 0.0])\n",
    "    if len(nr) > 0:\n",
    "        for ai in nr:\n",
    "            ma = np.array([ai.getX() - posX, ai.getY() - posY])\n",
    "            ma = normalize(ma, 1)\n",
    "            ds = ds - ma\n",
    "        #ds = - normalize(ds, 1)\n",
    "        label[0] = 1\n",
    "    if len(na) > 0:\n",
    "        for ai in na:\n",
    "            ma = np.array([ai.getX() - posX, ai.getY() - posY])\n",
    "            ma = normalize(ma, 1)\n",
    "            ds = ds + ma\n",
    "        #ds = normalize(ds, 1)\n",
    "        label[2] = 1\n",
    "    if len(no) > 0:\n",
    "        for ai in no:\n",
    "            ma = ai.velo\n",
    "            ma = normalize(ma, 1)\n",
    "            ds = ds + ma\n",
    "        #ds = normalize(ds, 1)\n",
    "        label[1] = 1\n",
    "    if len(na) > 0 or len(no) > 0 or len(nr) > 0:\n",
    "        ds = normalize(ds, 1)\n",
    "    m = normalize(aj.velo + 0.1 * ds, 1)\n",
    "    if posX - max_visual_range <= 0:\n",
    "        d = 0.0 - (posX - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        m[0] = m[0] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posX + max_visual_range >= winWidth:\n",
    "        d = (posX + max_visual_range) - winWidth\n",
    "        wd = d/max_visual_range\n",
    "        m[0] = m[0] + wd * -1\n",
    "        label[3] = 1\n",
    "    if posY - max_visual_range <= 0:\n",
    "        d = 0.0 - (posY - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        m[1] = m[1] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posY + max_visual_range >= winHeight:\n",
    "        d = (posY + max_visual_range) - winHeight\n",
    "        wd = d/max_visual_range\n",
    "        m[1] = m[1] + wd * -1\n",
    "        label[3] = 1\n",
    "    aj.label = label\n",
    "    m = add_noise(m)\n",
    "    o = np.arctan2(m[1], m[0])\n",
    "    return m, o\n",
    "\n",
    "#couzin with speed changes\n",
    "c_vs = np.ones(29) * 0.2\n",
    "def couzin_velomem(aj, agents, winWidth, winHeight, max_visual_range):\n",
    "    t_steps = 40 #c_vs.shape\n",
    "    zor_r = 15\n",
    "    zoo_r = 35\n",
    "    zoa_r = 45\n",
    "    max_visual_range = max_visual_range - 5\n",
    "    m = aj.velo\n",
    "    posX = aj.point.getCenter().getX()\n",
    "    posY = aj.point.getCenter().getY()\n",
    "    label = np.zeros((4))\n",
    "    nr, no, na = find_neighbors_zoi(aj, zor_r, zoo_r, zoa_r, agents)\n",
    "    ds = np.array([0.0, 0.0])\n",
    "    if len(nr) > 0:\n",
    "        for ai in nr:\n",
    "            aj.neighbours[ai.id] = t_steps\n",
    "            ma = np.array([ai.getX() - posX, ai.getY() - posY])\n",
    "            ma = normalize(ma, 1)\n",
    "            ds = ds - ma\n",
    "        #ds = - normalize(ds, 1)\n",
    "        label[0] = 1\n",
    "    if len(na) > 0:\n",
    "        for ai in na:\n",
    "            aj.neighbours[ai.id] = t_steps\n",
    "            ma = np.array([ai.getX() - posX, ai.getY() - posY])\n",
    "            ma = normalize(ma, 1)\n",
    "            ds = ds + ma\n",
    "        #ds = normalize(ds, 1)\n",
    "        label[2] = 1\n",
    "    if len(no) > 0:\n",
    "        for ai in no:\n",
    "            aj.neighbours[ai.id] = t_steps\n",
    "            ma = ai.velo\n",
    "            ma = normalize(ma, 1)\n",
    "            ds = ds + ma\n",
    "        #ds = normalize(ds, 1)\n",
    "        label[1] = 1\n",
    "    if label[1] == 1 or label[2] == 1 or label[0] == 1:\n",
    "        ds = normalize(ds, 1)\n",
    "        aj.future_vs[1:] = aj.future_vs[1:] + c_vs\n",
    "        aj.neighbourocc.append(t_steps)\n",
    "    velo = 1 + aj.future_vs[0]\n",
    "    #print(\"velo :\", velo)\n",
    "    for i, value in enumerate(aj.neighbours):\n",
    "        if value > 0:\n",
    "            aj.neighbours[i] = value - 1\n",
    "    for i, value in enumerate(aj.neighbourocc):\n",
    "        if value > 0:\n",
    "            aj.neighbourocc[i] = value - 1\n",
    "    for i, value in reversed(list(enumerate(aj.neighbourocc))):\n",
    "        if value < 1:\n",
    "            del aj.neighbourocc[i]\n",
    "    if velo-np.linalg.norm(aj.velo) > 1:\n",
    "        print(\"velo: \", velo)\n",
    "        print(\"aj.velo: \", aj.velo)\n",
    "        print(\"acceleration: \", velo-np.linalg.norm(aj.velo))\n",
    "    m = normalize(aj.velo + 0.1 * ds, velo)\n",
    "    aj.future_vs = aj.future_vs\n",
    "    if posX - max_visual_range <= 0:\n",
    "        d = 0.0 - (posX - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[0] = m[0] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posX + max_visual_range >= winWidth:\n",
    "        d = (posX + max_visual_range) - winWidth\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[0] = m[0] + wd * -1\n",
    "        label[3] = 1\n",
    "    if posY - max_visual_range <= 0:\n",
    "        d = 0.0 - (posY - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[1] = m[1] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posY + max_visual_range >= winHeight:\n",
    "        d = (posY + max_visual_range) - winHeight\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[1] = m[1] + wd * -1\n",
    "        label[3] = 1\n",
    "    aj.future_vs[:-1] = aj.future_vs[1:]\n",
    "    aj.future_vs[-1] = 0\n",
    "    aj.label = label\n",
    "    m = add_noise(m)\n",
    "    velolen = np.sqrt(m[0] * m[0] + m[1] * m[1])\n",
    "    aj.velospeed = velolen\n",
    "    o = np.arctan2(m[1], m[0])\n",
    "    return m, o\n",
    "\n",
    "#complex couzin\n",
    "def couzin_mem_diff(aj, agents, winWidth, winHeight, max_visual_range):\n",
    "    t_steps = 40\n",
    "    zor_r = 15\n",
    "    zoo_r = 35\n",
    "    zoa_r = 45\n",
    "    aj.repulsion_time = 0\n",
    "    if np.sum(aj.neighbours > 0) > 3:\n",
    "        zor_r = 45\n",
    "        aj.repulsion_time = 1\n",
    "    max_visual_range = max_visual_range - 5\n",
    "    m = aj.velo\n",
    "    posX = aj.point.getCenter().getX()\n",
    "    posY = aj.point.getCenter().getY()\n",
    "    label = np.zeros((4))\n",
    "    nr, no, na = find_neighbors_zoi(aj, zor_r, zoo_r, zoa_r, agents)\n",
    "    ds = np.array([0.0, 0.0])\n",
    "    if len(nr) > 0:\n",
    "        aj.neighbourocc.append(t_steps)\n",
    "        aj.future_vs[1:] = aj.future_vs[1:] + c_vs\n",
    "        for ai in nr:\n",
    "            aj.neighbours[ai.id] = t_steps\n",
    "            ma = np.array([ai.getX() - posX, ai.getY() - posY])\n",
    "            ma = normalize(ma, 1)\n",
    "            ds = ds + ma\n",
    "        ds = - normalize(ds, 1)\n",
    "        label[0] = 1\n",
    "    else:\n",
    "        if len(no) > 0: \n",
    "            for ai in no:\n",
    "                aj.neighbours[ai.id] = t_steps\n",
    "                if  aj.repulsion_time == 0:\n",
    "                    ma = ai.velo\n",
    "                    ma = normalize(ma, 1)\n",
    "                    ds = ds + ma\n",
    "            label[1] = 1\n",
    "        if len(na) > 0:\n",
    "            for ai in na:\n",
    "                aj.neighbours[ai.id] = t_steps\n",
    "                if  aj.repulsion_time == 0:\n",
    "                    ma = np.array([ai.getX() - posX, ai.getY() - posY])\n",
    "                    ma = normalize(ma, 1)\n",
    "                    ds = ds + ma\n",
    "            label[2] = 1\n",
    "        if label[1] == 1 or label[2] == 1:\n",
    "            if aj.repulsion_time == 0:\n",
    "                ds = normalize(ds, 1)\n",
    "            aj.future_vs[1:] = aj.future_vs[1:] + c_vs\n",
    "            aj.neighbourocc.append(t_steps)\n",
    "    if aj.repulsion_time == 0:\n",
    "        velo = 1 + aj.future_vs[0]\n",
    "    else:\n",
    "        velo = np.linalg.norm(aj.velo)\n",
    "    for i, value in enumerate(aj.neighbours):\n",
    "        if value > 0:\n",
    "            aj.neighbours[i] = value - 1\n",
    "    for i, value in enumerate(aj.neighbourocc):\n",
    "        if value > 0:\n",
    "            aj.neighbourocc[i] = value - 1\n",
    "    for i, value in reversed(list(enumerate(aj.neighbourocc))):\n",
    "        if value < 1:\n",
    "            del aj.neighbourocc[i]\n",
    "    if velo-np.linalg.norm(aj.velo) > 0.15:\n",
    "        velo = np.linalg.norm(aj.velo) + 0.15\n",
    "    m = normalize(aj.velo + 0.2 * ds, velo)\n",
    "    aj.future_vs = aj.future_vs\n",
    "    if posX - max_visual_range <= 0:\n",
    "        d = 0.0 - (posX - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[0] = m[0] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posX + max_visual_range >= winWidth:\n",
    "        d = (posX + max_visual_range) - winWidth\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[0] = m[0] + wd * -1\n",
    "        label[3] = 1\n",
    "    if posY - max_visual_range <= 0:\n",
    "        d = 0.0 - (posY - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[1] = m[1] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posY + max_visual_range >= winHeight:\n",
    "        d = (posY + max_visual_range) - winHeight\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[1] = m[1] + wd * -1\n",
    "        label[3] = 1\n",
    "    aj.future_vs[:-1] = aj.future_vs[1:]\n",
    "    aj.future_vs[-1] = 0\n",
    "    aj.label = label\n",
    "    m = add_noise(m)\n",
    "    velolen = np.linalg.norm(m)\n",
    "    if aj.repulsion_time > 0:\n",
    "        if aj.velospeed > 1:\n",
    "            velolen = max(0.5, velolen-0.15)\n",
    "            m = normalize(m, velolen)\n",
    "    aj.velospeed = velolen\n",
    "    o = np.arctan2(m[1], m[0])\n",
    "    return m, o\n",
    "\n",
    "\n",
    "#complex couzin OLD OLD OLD\n",
    "def couzin_mem_diff_OLD(aj, agents, winWidth, winHeight, max_visual_range):\n",
    "    t_steps = 40 #c_vs.shape\n",
    "    #print(np.sum(aj.neighbours > 0))\n",
    "    zor_r = 15\n",
    "    zoo_r = 35\n",
    "    zoa_r = 45\n",
    "    aj.repulsion_time = 0\n",
    "    # if we had at least 4 distinct labors in last n steps: repulsion time\n",
    "    if np.sum(aj.neighbours > 0) > 3:\n",
    "        zor_r = 45\n",
    "        aj.repulsion_time = 1\n",
    "    max_visual_range = max_visual_range - 5\n",
    "    m = aj.velo\n",
    "    posX = aj.point.getCenter().getX()\n",
    "    posY = aj.point.getCenter().getY()\n",
    "    label = np.zeros((4))\n",
    "    nr, no, na = find_neighbors_zoi(aj, zor_r, zoo_r, zoa_r, agents)\n",
    "    ds = np.array([0.0, 0.0])\n",
    "    #we only consider Repulsion Zone if agents are inside repulsion sides\n",
    "    if len(nr) > 0:\n",
    "        aj.neighbourocc.append(t_steps)\n",
    "        aj.future_vs[1:] = aj.future_vs[1:] + c_vs\n",
    "        for ai in nr:\n",
    "            aj.neighbours[ai.id] = t_steps\n",
    "            ma = np.array([ai.getX() - posX, ai.getY() - posY])\n",
    "            ma = normalize(ma, 1)\n",
    "            ds = ds + ma\n",
    "        ds = - normalize(ds, 1)\n",
    "        label[0] = 1\n",
    "    else:\n",
    "        if len(no) > 0: \n",
    "            for ai in no:\n",
    "                aj.neighbours[ai.id] = t_steps\n",
    "                if  aj.repulsion_time == 0:\n",
    "                    ma = ai.velo\n",
    "                    ma = normalize(ma, 1)\n",
    "                    ds = ds + ma\n",
    "            label[1] = 1\n",
    "        if len(na) > 0:\n",
    "            for ai in na:\n",
    "                aj.neighbours[ai.id] = t_steps\n",
    "                if  aj.repulsion_time == 0:\n",
    "                    ma = np.array([ai.getX() - posX, ai.getY() - posY])\n",
    "                    ma = normalize(ma, 1)\n",
    "                    ds = ds + ma\n",
    "            label[2] = 1\n",
    "        if label[1] == 1 or label[2] == 1:\n",
    "            if aj.repulsion_time == 0:\n",
    "                ds = normalize(ds, 1)\n",
    "            aj.future_vs[1:] = aj.future_vs[1:] + c_vs\n",
    "            aj.neighbourocc.append(t_steps)\n",
    "    velo = 1 + aj.future_vs[0]\n",
    "    for i, value in enumerate(aj.neighbours):\n",
    "        if value > 0:\n",
    "            aj.neighbours[i] = value - 1\n",
    "    for i, value in enumerate(aj.neighbourocc):\n",
    "        if value > 0:\n",
    "            aj.neighbourocc[i] = value - 1\n",
    "    for i, value in reversed(list(enumerate(aj.neighbourocc))):\n",
    "        if value < 1:\n",
    "            del aj.neighbourocc[i]\n",
    "    m = normalize(aj.velo + 0.2 * ds, velo)\n",
    "    aj.future_vs = aj.future_vs\n",
    "    if posX - max_visual_range <= 0:\n",
    "        d = 0.0 - (posX - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[0] = m[0] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posX + max_visual_range >= winWidth:\n",
    "        d = (posX + max_visual_range) - winWidth\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[0] = m[0] + wd * -1\n",
    "        label[3] = 1\n",
    "    if posY - max_visual_range <= 0:\n",
    "        d = 0.0 - (posY - max_visual_range)\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[1] = m[1] + wd * 1\n",
    "        label[3] = 1\n",
    "    if posY + max_visual_range >= winHeight:\n",
    "        d = (posY + max_visual_range) - winHeight\n",
    "        wd = d/max_visual_range\n",
    "        wd = wd * velo\n",
    "        m[1] = m[1] + wd * -1\n",
    "        label[3] = 1\n",
    "    aj.future_vs[:-1] = aj.future_vs[1:]\n",
    "    aj.future_vs[-1] = 0\n",
    "    aj.label = label\n",
    "    m = add_noise(m)\n",
    "    velolen = np.sqrt(m[0] * m[0] + m[1] * m[1]) \n",
    "    if aj.repulsion_time > 0:\n",
    "        if aj.velospeed > 1:\n",
    "            velolen = max(0.5, velolen-1)\n",
    "            m = normalize(m, velolen)\n",
    "            if velolen < 1:\n",
    "                aj.repulsion_time = 0\n",
    "    \n",
    "    aj.velospeed = velolen\n",
    "    o = np.arctan2(m[1], m[0])\n",
    "    return m, o\n",
    "\n",
    "\n",
    "###################################### Movement Models END ######################################\n",
    "\n",
    "def run_complexrnn(aj, num_features, m, o):\n",
    "    #rnn.zero_grad()\n",
    "    global Y_HIST\n",
    "    windows = 10\n",
    "    X = (np.asarray(aj.history[-windows:]))\n",
    "    X = X[:, 6+4:]\n",
    "    dx = np.zeros((2, windows, num_features))\n",
    "    dx[0, :, :] = X\n",
    "    dx[1, :, :] = X\n",
    "    X = dx.astype(np.float32)\n",
    "    X = torch.from_numpy(X)\n",
    "    X = torch.autograd.Variable(X).cuda()\n",
    "    Y, hidden = rnn.forward(X, verbose=False)\n",
    "    pi, sigma, mu = Y \n",
    "    Y = getMeanSample(pi, sigma, mu) \n",
    "    Y = MDN.sample(pi, sigma, mu)\n",
    "    Y = Y[0, :].cpu().data.numpy()\n",
    "    dx = Y[0]\n",
    "    dy = Y[1]\n",
    "    dxt, dyt = dx, dy\n",
    "    aj.velo = np.array([dxt, dyt]) \n",
    "    newOrientation = np.arctan2(Y[3], Y[2]) \n",
    "    if newOrientation > np.pi:\n",
    "        newOrientation = - np.pi + (newOrientation - np.pi)\n",
    "    if newOrientation < -np.pi:\n",
    "        newOrientation =  np.pi - (- np.pi - newOrientation)\n",
    "    aj.setOrientationO(newOrientation)\n",
    "    aj.setOrientationO(np.arctan2(dy, dx))\n",
    "\n",
    "\n",
    "    \n",
    "def assimilate_velott(aj, agents):\n",
    "    \"\"\"Calculate the new velocity for a single agent by looking at the velocity of the nearest neighbour.\"\"\"\n",
    "    oldO = aj.orientation\n",
    "    oldm = aj.velo\n",
    "    w = 0.2\n",
    "    ai = find_nearest_neighbor(aj, agents)\n",
    "    m = aj.velo + w*np.array([ai.velo[0], ai.velo[1]])\n",
    "    m = normalize(m, 1)\n",
    "    o = np.arctan2(m[0], m[1])\n",
    "    dm = m\n",
    "    do = angle_between_rad(o, oldO)\n",
    "    dxo, dyo = np.cos(do), np.sin(do)\n",
    "    dxt, dyt = transformCordinateSystem(oldO, dm[0], dm[1])\n",
    "    # dxt, dyt, dxo, dyo entspricht perfekter vorhersage\n",
    "    \n",
    "    dx, dy = transformCordinateSystem(-oldO, dxt, dyt)\n",
    "    aj.velo = np.array([dx, dy]) #normalize(np.array([dxt, dyt]), 2) \n",
    "    newOrientation = oldO + np.arctan2(dyo, dxo)\n",
    "    if newOrientation > np.pi:\n",
    "        newOrientation = - np.pi + (newOrientation - np.pi)\n",
    "    if newOrientation < -np.pi:\n",
    "        newOrientation =  np.pi - (- np.pi - newOrientation)\n",
    "    aj.setOrientationO(newOrientation)  \n",
    "    \n",
    "\n",
    "\n",
    "def find_nearest_neighbor(aj, agents): \n",
    "    \"\"\"Nearest neighbor for agents.\"\"\"\n",
    "    distances = [np.linalg.norm(np.array([aj.point.getCenter().getX(), aj.point.getCenter().getY()]) -\n",
    "                                np.array([ai.point.getCenter().getX(), ai.point.getCenter().getY()])) for ai in agents]\n",
    "    distances[distances.index(0.0)] = 99999999999999999\n",
    "    return agents[distances.index(min(distances))],  distances[distances.index(min(distances))]\n",
    "\n",
    "def find_k_nearest_neighbor(aj, k, agents): \n",
    "    \"\"\"K-nearest neighbor function for agents.\"\"\"\n",
    "    distances = [np.linalg.norm(np.array([aj.point.getCenter().getX(), aj.point.getCenter().getY()]) -\n",
    "                                np.array([ai.point.getCenter().getX(), ai.point.getCenter().getY()])) for ai in agents]\n",
    "    sorted_distances = np.sort(distances)\n",
    "    neighbours = []\n",
    "    for x in sorted_distances[1:k+1]:\n",
    "        neighbours.append(agents[distances.index(x)])\n",
    "    return (neighbours)\n",
    "\n",
    "\n",
    "Y_HIST = np.zeros((1, 4))\n",
    "def run_bee_net(aj, num_features):\n",
    "    rnn.zero_grad()\n",
    "    global Y_HIST\n",
    "    windows = 2\n",
    "    X = (np.asarray(aj.history[-windows:]))\n",
    "    X = X[:, 6:]\n",
    "    print(\"X: \", X[:, :5])\n",
    "    dx = np.ones((2, windows, num_features)) * 0.333\n",
    "    dx[0, :, :] = X\n",
    "    dx[1, :, :] = X\n",
    "    X = dx.astype(np.float32)\n",
    "    X = torch.from_numpy(X)\n",
    "    X = torch.autograd.Variable(X).cuda()\n",
    "    Y, hidden = rnn.forward(X, verbose=False)\n",
    "    pi, sigma, mu = Y \n",
    "    Y = MDN.sample(pi, sigma, mu)\n",
    "    Y = Y[0, :].cpu().data.numpy()\n",
    "    Y_HIST.append(Y)\n",
    "    print(\"Prediction: \", Y)\n",
    "    dx = Y[0]\n",
    "    dy = Y[1]\n",
    "    dxt, dyt = dx, dy\n",
    "    aj.velo = np.array([dxt, dyt]) \n",
    "    newOrientation = np.arctan2(Y[3], Y[2]) #aj.orientation + np.arctan2(Y[3], Y[2])\n",
    "    if newOrientation > np.pi:\n",
    "        newOrientation = - np.pi + (newOrientation - np.pi)\n",
    "    if newOrientation < -np.pi:\n",
    "        newOrientation =  np.pi - (- np.pi - newOrientation)\n",
    "    aj.setOrientationO(newOrientation)\n",
    "\n",
    "\n",
    "    \n",
    "def saveNetworkTimestep(t_save, network_historys):\n",
    "    ts = np.ones((historys.shape[0], 1, 3)) * -1000\n",
    "    for ai in agents:  \n",
    "        x = ai.getX()\n",
    "        y = ai.getY()\n",
    "        o = ai.orientation\n",
    "        ts[ai.id, 0] = x, y, o\n",
    "    network_historys = np.concatenate((network_historys, ts), 1)\n",
    "    print(network_historys.shape)\n",
    "    return network_historys\n",
    "    \n",
    "def avoid_border_crossing(aj, winWidth, winHeight):\n",
    "    if aj.point.getCenter().getX() + aj.velo[0] <= 0 or aj.point.getCenter().getX() + aj.velo[0] >= winWidth:\n",
    "        aj.velo[0] = aj.velo[0]*(-1)\n",
    "        print(\"X CROSS\")\n",
    "    if aj.point.getCenter().getY() + aj.velo[1] <= 0 or aj.point.getCenter().getY() + aj.velo[1] >= winHeight:\n",
    "        aj.velo[1] = aj.velo[1]*(-1)\n",
    "        print(\"Y CROSS\")\n",
    "    \n",
    "def update_agents(algorithm, window, winWidth, winHeight, draw, switch, OSHistory, vision_bins, max_visual_range):\n",
    "    global network_historys\n",
    "    num_features = 5 + vision_bins * 8 #8\n",
    "    if timestep == switch and algorithm == 7:\n",
    "        agents[:] = [aj for aj in agents if not len(aj.history) < 34]\n",
    "        draw_agents(window, draw)\n",
    "        network_historys = np.ones(((historys.shape[0], 0, 3))) * (-1000)\n",
    "        #time.sleep(10)\n",
    "    for aj in agents:\n",
    "        if algorithm == 0:\n",
    "            if timestep < switch:\n",
    "                simple_step(aj, agents)\n",
    "            else:\n",
    "                m, o = constant_step(aj, agents, winWidth, winHeight, max_visual_range)\n",
    "                aj.velo = m\n",
    "                aj.setOrientationO(o)\n",
    "        elif algorithm == 1:\n",
    "            if timestep < switch:\n",
    "                simple_step(aj, agents)\n",
    "            else:\n",
    "                m, o = couzin(aj, agents, winWidth, winHeight, max_visual_range)\n",
    "                aj.velo = m\n",
    "                aj.setOrientationO(o)\n",
    "        elif algorithm == 2:\n",
    "            if timestep < switch:\n",
    "                simple_step(aj, agents)\n",
    "            else:\n",
    "                m, o = couzin_velomem(aj, agents, winWidth, winHeight, max_visual_range)\n",
    "                aj.velo = m\n",
    "                aj.setOrientationO(o)\n",
    "        elif algorithm == 3:\n",
    "            window_step(aj)\n",
    "            time.sleep(0.01)\n",
    "        elif algorithm == 4:\n",
    "            if timestep < switch:\n",
    "                simple_step(aj, agents)\n",
    "            else:\n",
    "                m, o = couzin(aj, agents, winWidth, winHeight, max_visual_range)\n",
    "                run_complexrnn(aj, num_features, m, o)        \n",
    "        elif algorithm == 5:\n",
    "            if timestep < switch:\n",
    "                simple_step(aj, agents)\n",
    "            else:\n",
    "                m, o = couzin_mem_diff(aj, agents, winWidth, winHeight, max_visual_range)\n",
    "                aj.velo = m\n",
    "                aj.setOrientationO(o)\n",
    "\n",
    "        elif algorithm == 6:\n",
    "            if timestep < switch:\n",
    "                simple_step(aj, agents)\n",
    "            else:\n",
    "                m, o = couzin_mem_diff(aj, agents, winWidth, winHeight, max_visual_range)\n",
    "                run_complexrnn(aj, num_features, m, o)\n",
    "        elif algorithm == 9:\n",
    "            if timestep < switch:\n",
    "                real_step(aj, agents, window)\n",
    "            else:\n",
    "                m, o = couzin(aj, agents, winWidth, winHeight, max_visual_range)\n",
    "                run_complexrnn(aj, num_features, m, o)\n",
    "        else:\n",
    "            print(\"No algorithm specified\")\n",
    "            return\n",
    "    if timestep >= switch and algorithm == 7:\n",
    "        network_historys = saveNetworkTimestep(timestep-switch, network_historys)\n",
    "        \n",
    "        \n",
    "def update_vision(max_visual_range, vision_bins, borders, OSHistory, verbose = True):\n",
    "    positions = np.asarray([[ai.getX(), ai.getY(), ai] for ai in agents])\n",
    "    neighbours= spatial.cKDTree(positions[:,:2]).query_ball_point(positions[:,:2], max_visual_range)\n",
    "    for j, pos in enumerate(positions):\n",
    "        currstate = pos[2].getCurrState(vision_bins)\n",
    "        OSHistory.save(currstate[4], currstate)\n",
    "    for j, pos in enumerate(positions):\n",
    "        if (positions[j,0]<0 or positions[j, 1]<0):\n",
    "            pos[2].vision = np.zeros(vision_bins*8)\n",
    "        else:\n",
    "            cur_neighbours = [x for x in neighbours[j] if x != j] \n",
    "            neighbour_positions = positions[cur_neighbours]\n",
    "            neighbour_positions = np.asarray([n.getCurrState(vision_bins) for n in neighbour_positions[:, 2]])\n",
    "            beesurr = getBeeSurroundings(pos[2].getCurrState(vision_bins), neighbour_positions, OSHistory, max_visual_range, vision_bins, verbose = verbose, borders = borders)\n",
    "            pos[2].vision = beesurr\n",
    "            \n",
    "def update_vision_wall(max_visual_range, vision_bins, borders, OSHistory, verbose = True):\n",
    "    positions = np.asarray([[ai.getX(), ai.getY(), ai] for ai in agents])\n",
    "    for j, pos in enumerate(positions):\n",
    "        currstate = pos[2].getCurrState(vision_bins)\n",
    "        OSHistory.save(currstate[4], currstate)\n",
    "    for j, pos in enumerate(positions):\n",
    "        if (positions[j,0]<0 or positions[j, 1]<0):\n",
    "            pos[2].vision = np.zeros(vision_bins*8)\n",
    "        else:\n",
    "            beesurr = getBeeSurroundings(pos[2].getCurrState(vision_bins), [], OSHistory, max_visual_range, vision_bins, verbose = verbose, borders = borders)\n",
    "            pos[2].vision = beesurr\n",
    "            \n",
    "#bins_distance, bins_SINorientation, bins_COSorientation, bins_activity, \n",
    "#bins_binary, bins_relativeOsin, bins_relativeOcos, borders\n",
    "def decode_beeSurroundings_wall(aj, vision, max_visual_range, window, num_bins = 36, borders=[[0,0], [370, 370]]):\n",
    "    \"\"\"\n",
    "    Seperate environment of an agent into bins and find nearest neighbour for all bins.\n",
    "    Add orientation and activity of the neighbour bees.\n",
    "    \"\"\"\n",
    "    posX = aj.getX()\n",
    "    posY = aj.getY()\n",
    "    orientation = aj.orientation\n",
    "    bin_distance = 360/num_bins\n",
    "    angles = np.linspace(-180+bin_distance/2, 180-bin_distance/2, num_bins, endpoint=True)\n",
    "    print(\"a\", angles.shape)\n",
    "    angles = np.radians(angles)\n",
    "    ovec = np.array([np.sin(orientation), np.cos(orientation)])\n",
    "    target_dirs = [normalize(turn_vector(ovec, angle), max_visual_range) for angle in angles]\n",
    "    #borders = get_walls_in_sight(np.array([posX, posY]), orientation, max_visual_range, num_bins, borders)\n",
    "    wall_borders = vision[7*num_bins:8*num_bins]\n",
    "    print(\"x, y: \", posX, \", \", posY)\n",
    "    print(\"WB\", wall_borders)\n",
    "    print(\"wb\", wall_borders.shape)\n",
    "    for i, direction in enumerate(target_dirs):\n",
    "        print(i)\n",
    "        aj.wlines[i].undraw()\n",
    "        aj.wlines[i] = Line(aj.point.getCenter(), Point(aj.getX() + direction[0], aj.getY() + direction[1]))\n",
    "        aj.wlines[i].setFill('blue')\n",
    "        aj.wlines[i].draw(window)\n",
    "        if wall_borders[i] > 0.0:\n",
    "            aj.wlines[i].setFill('green')\n",
    "            print(\"i, direction\", i, \", \", direction)\n",
    "\n",
    "\n",
    "\n",
    "def decode_beeSurroundings(aj, vision, max_visual_range, window, num_bins = 36, borders=[[0,0], [370, 370]]):\n",
    "    posX = aj.getX()\n",
    "    posY = aj.getY()\n",
    "    orientation = aj.orientation\n",
    "    bins_distance = vision[0:num_bins]\n",
    "    bins_SINorientation = vision[num_bins:2*num_bins]\n",
    "    bins_COSorientation = vision[2*num_bins:3*num_bins]\n",
    "    bins_activity = vision[3*num_bins:4*num_bins]\n",
    "    bins_binary = vision[4*num_bins:5*num_bins]\n",
    "    print(\"--------------------------\")\n",
    "    print(\"X, Y, o: \", posX, posY, orientation)\n",
    "    print(\"coso, sino\", np.cos(orientation), np.sin(orientation))\n",
    "    print(\"bins_binary: \", bins_binary) # 5\n",
    "    print(\"bins_sino: \", bins_SINorientation) # 5\n",
    "    print(\"bins_coso: \", bins_COSorientation) # 5\n",
    "    print(\"bins_activity: \", bins_activity) # 5\n",
    "    angle_borders = np.linspace(-180, 180, num_bins + 1)\n",
    "    angles = np.radians(angle_borders)\n",
    "    ovec = np.array([np.cos(orientation), np.sin(orientation)])\n",
    "    target_dirs = [normalize(turn_vector(ovec, -angle), max_visual_range) for angle in angles] #6 -2*np.pi/5\n",
    "    #print(target_dirs)\n",
    "    bin_distance = 360/num_bins\n",
    "    ds = np.zeros(num_bins+1) # 6\n",
    "    for i in range(0, num_bins):\n",
    "        if bins_binary[i] > 0.5:\n",
    "            ds[i] = bins_distance[i] * max_visual_range\n",
    "            ds[i+1] =bins_distance[i] * max_visual_range #i +i+1 must be drawn\n",
    "            \n",
    "    #bins_distance[i] * max_visual_range= max_visual_range - np.linalg.norm(sight_vector)\n",
    "    if ds[0]< ds[-1]:\n",
    "        ds[0] = ds[-1]\n",
    "    else:\n",
    "        ds[-1] = ds[0]\n",
    "    #ds[0] = 1\n",
    "    #ds[-1] = 1\n",
    "    print(\"ds\", ds)\n",
    "    for i, direction in enumerate(target_dirs):\n",
    "        direction = normalize(direction, 50) #ds[i])\n",
    "        aj.vlines[i].undraw()\n",
    "        aj.vlines[i] = Line(aj.point.getCenter(), Point(aj.getX() + direction[0], aj.getY() + direction[1]))\n",
    "        aj.vlines[i].setFill('black')\n",
    "        aj.vlines[i].draw(window)\n",
    "        if ds[i] > 0.0:\n",
    "            aj.vlines[i].setFill('red')\n",
    "        #    print(\"i, direction\", i, \", \", direction)\n",
    "        #bins[i] = max(0, 1 - np.linalg.norm(position-intersection_point)/radius)\n",
    "\n",
    "def normalize(vec, norm):\n",
    "    \"\"\"Normalizes the vector and multiplies it with norm.\"\"\"\n",
    "    if np.linalg.norm(vec) == 0:\n",
    "        print(\"normalize with zero vector\")\n",
    "        return vec\n",
    "    return(norm*vec/np.linalg.norm(vec))\n",
    "\n",
    "\n",
    "def update_vision_z(max_visual_range, vision_bins, OSHistory, verbose = True):\n",
    "    for ai in agents:\n",
    "        ai.vision = np.zeros(8*vision_bins)\n",
    "            \n",
    "### Simulation\n",
    "def do_simulation(num_agents, winWidth, winHeight, num_timesteps, algorithm, vision_bins, max_visual_range, switch, OSHistory, draw = True, save_positions=False):\n",
    "    borders = [[0,0], [winWidth, winHeight]]\n",
    "    global timestep\n",
    "    timestep = 0\n",
    "    win = 0\n",
    "    if draw == True:\n",
    "        win = GraphWin(\"Window\", winWidth, winHeight, autoflush=False)\n",
    "        win.setBackground('white')\n",
    "    initialize(num_agents, win, winWidth, winHeight, vision_bins, draw, algorithm)\n",
    "    for i in range(num_timesteps):\n",
    "        #time.sleep(0.2)\n",
    "        if draw == True:\n",
    "            print(\"Timesteps: \", i)\n",
    "        if timestep < 2:\n",
    "            #time.sleep(2)\n",
    "            update_vision(max_visual_range, vision_bins, borders, OSHistory, verbose = False)\n",
    "            #update_vision_wall(max_visual_range, vision_bins, borders, OSHistory, verbose = False)\n",
    "        else:\n",
    "            update_vision(max_visual_range, vision_bins, borders, OSHistory, verbose = True)\n",
    "            #update_vision_wall(max_visual_range, vision_bins, borders, OSHistory, verbose = True)\n",
    "        update_agents(algorithm, win, winWidth, winHeight, draw, switch, OSHistory, vision_bins, max_visual_range)\n",
    "        if timestep > 5:\n",
    "            for ai in agents:\n",
    "                ai.appendTimestep(OSHistory, vision_bins)\n",
    "        for ai in agents:\n",
    "            avoid_border_crossing(ai, winWidth, winHeight)\n",
    "            move_agent(ai, win, draw, algorithm)\n",
    "        if False:\n",
    "            for aj in agents:\n",
    "                decode_beeSurroundings(aj, aj.vision, 100, win, vision_bins, borders)\n",
    "                #decode_beeSurroundings_wall(aj, aj.vision, 100, win, vision_bins, borders)\n",
    "        if draw == True:\n",
    "            win.update()\n",
    "        #time.sleep(0.1)\n",
    "        timestep = timestep + 1\n",
    "    if draw == True:\n",
    "        win.close()\n",
    "        win.update()\n",
    "    return agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISION -> APPEND TIMESTEP(labels saved) -> Move_AGENTS(Labels generated) -> Vision\n",
    "VISION_T Data_T Label_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vs = np.array([0.01, 0.01, 0.02, 0.02, 0.03, 0.03, 0.04, 0.04, 0.05, 0.05, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.1, 0.1, 0.1,\n",
    "       0.1, 0.1, 0.1, 0.1, 0.1, 0.09, 0.08, 0.07, 0.06, 0.05, 0.05, 0.05, 0.04, 0.04, 0.03, 0.03, 0.02, 0.02, 0.01, 0.01])\n",
    "c_vs = c_vs * 3\n",
    "c_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vs = np.zeros(39)\n",
    "c_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vs = np.array([0.1, 0.1, 0.2, 0.2, 0.3, 0.3, 0.4, 0.4, 0.5, 0.6, 0.7, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8,\n",
    "       0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.7, 0.6, 0.5, 0.5, 0.5, 0.4, 0.4, 0.3, 0.3, 0.2, 0.2, 0.1, 0.1])\n",
    "c_vs = c_vs * 1\n",
    "c_vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn = SimpleRNN(n_features=5 + (vision_bins * 8), n_outputs=4).cuda()\n",
    "rnn = SimpleRNN(n_features=5 +(vision_bins * 8), n_outputs=4).cuda()\n",
    "#rnn = torch.load('simplemodel-rnn.pt')\n",
    "#rnn = torch.load('couzinmodel-rnn.pt')\n",
    "#rnn = torch.load('couzinvelomodel-rnn.pt')\n",
    "#rnn = torch.load('complexcouzin-rnn.pt')\n",
    "rnn = torch.load('bee40-rnn.pt')\n",
    "optimizer = torch.optim.RMSprop(rnn.parameters(), lr=0.0001)\n",
    "running_loss = 0.0\n",
    "#criterion = torch.nn.SmoothL1Loss()\n",
    "#criterion.cuda("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rec_losses = []\n",
    "\n",
    "import torch\n",
    "winWidth = 550\n",
    "winHeight = 550\n",
    "T = 2500\n",
    "N = 30\n",
    "track_ids = np.arange(N)\n",
    "vision_bins = 16\n",
    "max_visual_range = 50\n",
    "l = len(track_ids)\n",
    "for i in range(0, l):\n",
    "    track_ids[i] = i\n",
    "num_features = 5 + (vision_bins * 8)\n",
    "OSHistory = OneStepBeeHistory(5 +2+(vision_bins * 8), track_ids)\n",
    "#scale = 2\n",
    "#rnn = torch.load(\"complexrnn.pt\")\n",
    "#rnn.eval() # evaluation mode\n",
    "algorithm = 3 #5\n",
    "#Attention: If bee RNN is run the visual range must be 20\n",
    "#0: Simple Model             1: Simple Couzin\n",
    "#2: Couzin Velo              3: windows step \n",
    "#4: RNN                      5: Complex Couzin\n",
    "#6: RNN for CC\n",
    "#9: Init with real data and run real data.\n",
    "switch = 50\n",
    "start = time.time()\n",
    "do_simulation(N, winWidth, winHeight, T, algorithm, vision_bins, max_visual_range, switch, OSHistory,draw = True)\n",
    "end = time.time()\n",
    "print(\"Time in seconds: \", end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "warnings.filterwarnings('ignore')\n",
    "rec_losses = []\n",
    "def generate_train_data(runs):\n",
    "    start = time.time()\n",
    "    vision_bins = 16\n",
    "    max_visual_range = 50\n",
    "    window_size = 40\n",
    "    img_dtype = tables.Float64Atom()  # dtype in which the images will be saved\n",
    "    data_shape = (0, window_size -1, 5 + 6 + 4 + (vision_bins * 8))\n",
    "    #data_shape = (0, window_size -1, 5 + 6 + (vision_bins*1))\n",
    "    with tables.open_file('pathtofile.h5', mode='a') as hdf5_file:\n",
    "        #hdf5_file.create_earray(hdf5_file.root, 'train', img_dtype, shape = data_shape)\n",
    "        print(hdf5_file.root.train.shape)\n",
    "        for j in range(0, runs):\n",
    "            print(j)\n",
    "            N = random.randint(1, 35)\n",
    "            track_ids = np.arange(N)\n",
    "            for i in range(0, N):\n",
    "                track_ids[i] = i\n",
    "            OSHistory = OneStepBeeHistory(5 + 2 + (vision_bins * 8), track_ids)\n",
    "            T = random.randint(300, 1200)\n",
    "            switch = 5\n",
    "            algorithm = 5\n",
    "            W = random.randint(350, 550)\n",
    "            winWidth, winHeight = W, W\n",
    "            do_simulation(N, winWidth, winHeight, T, algorithm, vision_bins, max_visual_range, switch, OSHistory, draw = False)\n",
    "            for aj in agents:\n",
    "                track = np.asarray(aj.history)\n",
    "                for i in range(35, len(track)-window_size, 2):\n",
    "                    #print(track[None, i: i+window_size -1].shape)\n",
    "                    hdf5_file.root.train.append(track[None, i: i+window_size -1])\n",
    "    end = time.time()\n",
    "    print(\"Time in seconds: \", end - start)\n",
    "    hdf5_file.close()    \n",
    "generate_train_data(215)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "10# Random shuffle the training data on the hard disk, for large data sets, this takes ages\n",
    "import random\n",
    "import time\n",
    "import tables\n",
    "import numpy as np\n",
    "start = time.time()\n",
    "hdf5_file = tables.open_file('pathtofile.h5', mode='a')\n",
    "print(hdf5_file.root.train.shape)\n",
    "print(hdf5_file.root.train[0:10, :, :])\n",
    "random.shuffle(hdf5_file.root.train)\n",
    "print(hdf5_file.root.train.shape)\n",
    "print(hdf5_file.root.train[0:10, :, :])\n",
    "hdf5_file.close()\n",
    "end = time.time()\n",
    "hdf5_file.close()\n",
    "print(\"Time in seconds for shuffle: \", end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
